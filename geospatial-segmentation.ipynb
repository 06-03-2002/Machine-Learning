{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:27.309362Z",
     "iopub.status.busy": "2025-03-28T23:19:27.309075Z",
     "iopub.status.idle": "2025-03-28T23:19:32.953272Z",
     "shell.execute_reply": "2025-03-28T23:19:32.952384Z",
     "shell.execute_reply.started": "2025-03-28T23:19:27.309340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set Dataset Path\n",
    "DATASET_PATH = \"/kaggle/input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset\"\n",
    "\n",
    "#  Define Device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:36.382671Z",
     "iopub.status.busy": "2025-03-28T23:19:36.382232Z",
     "iopub.status.idle": "2025-03-28T23:19:36.565809Z",
     "shell.execute_reply": "2025-03-28T23:19:36.564952Z",
     "shell.execute_reply.started": "2025-03-28T23:19:36.382644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 0 images & 0 masks\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m dataset \u001b[38;5;241m=\u001b[39m AerialDataset(DATASET_PATH, transform\u001b[38;5;241m=\u001b[39mimage_transform)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#  Create DataLoader\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Dataset loaded with resized images & corrected masks!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Asus\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Asus\\miniconda3\\envs\\dl\\Lib\\site-packages\\torch\\utils\\data\\sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    166\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "#  Define Transformations for Images\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),  # Resize images\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize RGB channels\n",
    "])\n",
    "\n",
    "#  Class to Load Dataset\n",
    "class AerialDataset(Dataset):\n",
    "    def __init__(self, dataset_path, transform=None):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.mask_paths = []\n",
    "\n",
    "        # Loop through all tiles (Tile 1 to Tile 8)\n",
    "        for tile_num in range(1, 9):  \n",
    "            tile_path = os.path.join(self.dataset_path, f\"Tile {tile_num}\")\n",
    "            img_folder = os.path.join(tile_path, \"images\")\n",
    "            mask_folder = os.path.join(tile_path, \"masks\")\n",
    "\n",
    "            if os.path.exists(img_folder) and os.path.exists(mask_folder):\n",
    "                images = sorted(os.listdir(img_folder))\n",
    "                masks = sorted(os.listdir(mask_folder))\n",
    "\n",
    "                for img_file, mask_file in zip(images, masks):\n",
    "                    self.image_paths.append(os.path.join(img_folder, img_file))\n",
    "                    self.mask_paths.append(os.path.join(mask_folder, mask_file))\n",
    "\n",
    "        print(f\" Loaded {len(self.image_paths)} images & {len(self.mask_paths)} masks\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        #  Load image & mask\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # Convert mask to grayscale\n",
    "\n",
    "        #  Resize both image and mask to 512x512\n",
    "        image = image.resize((512, 512), Image.BILINEAR)\n",
    "        mask = mask.resize((512, 512), Image.NEAREST)  # Keep mask integer values\n",
    "\n",
    "        #  Convert to tensor\n",
    "        image = image_transform(image)\n",
    "        mask = np.array(mask, dtype=np.uint8)  # Convert mask to NumPy array\n",
    "\n",
    "        #  Fix Mask Values: Convert grayscale [45, 92, ...] â†’ Class Labels [0-5]\n",
    "        mapping = {45: 0, 92: 1, 155: 2, 171: 3, 172: 4, 212: 5}  # Define mapping\n",
    "        mask_mapped = np.zeros_like(mask, dtype=np.uint8)  # Empty mask\n",
    "        for k, v in mapping.items():\n",
    "            mask_mapped[mask == k] = v  # Apply mapping\n",
    "\n",
    "        #  Convert back to tensor\n",
    "        mask_tensor = torch.tensor(mask_mapped, dtype=torch.long)\n",
    "\n",
    "        return image, mask_tensor\n",
    "\n",
    "#  Load Dataset\n",
    "dataset = AerialDataset(DATASET_PATH, transform=image_transform)\n",
    "\n",
    "#  Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "print(\" Dataset loaded with resized images & corrected masks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:41.355686Z",
     "iopub.status.busy": "2025-03-28T23:19:41.355397Z",
     "iopub.status.idle": "2025-03-28T23:19:41.528288Z",
     "shell.execute_reply": "2025-03-28T23:19:41.527417Z",
     "shell.execute_reply.started": "2025-03-28T23:19:41.355665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_image, sample_mask = dataset[0]  # Load first image-mask pair\n",
    "print(f\"Fixed unique values in the mask: {torch.unique(sample_mask)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:45.964767Z",
     "iopub.status.busy": "2025-03-28T23:19:45.964452Z",
     "iopub.status.idle": "2025-03-28T23:19:51.005011Z",
     "shell.execute_reply": "2025-03-28T23:19:51.004053Z",
     "shell.execute_reply.started": "2025-03-28T23:19:45.964742Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  Load Pretrained DeepLabV3+ Model\n",
    "model = models.segmentation.deeplabv3_resnet101(weights=models.segmentation.DeepLabV3_ResNet101_Weights.DEFAULT)\n",
    "\n",
    "#  Modify final classifier for number of classes\n",
    "num_classes = 6  # Change this based on your dataset\n",
    "model.classifier[4] = nn.Conv2d(256, num_classes, kernel_size=(1,1))\n",
    "\n",
    "#  Move Model to GPU if available\n",
    "model.to(device)\n",
    "\n",
    "print(\" Model loaded and ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:53.894680Z",
     "iopub.status.busy": "2025-03-28T23:19:53.894385Z",
     "iopub.status.idle": "2025-03-28T23:19:53.900651Z",
     "shell.execute_reply": "2025-03-28T23:19:53.899851Z",
     "shell.execute_reply.started": "2025-03-28T23:19:53.894659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#  Define Loss Function (CrossEntropyLoss for segmentation)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#  Use Adam Optimizer for better learning\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "print(\" Loss function & optimizer set up!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:19:56.700649Z",
     "iopub.status.busy": "2025-03-28T23:19:56.700310Z",
     "iopub.status.idle": "2025-03-28T23:27:22.012319Z",
     "shell.execute_reply": "2025-03-28T23:27:22.011558Z",
     "shell.execute_reply.started": "2025-03-28T23:19:56.700621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 10  # Change based on your needs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, masks in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        images, masks = images.to(device), masks.to(device)  # Move to GPU if available\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)[\"out\"]\n",
    "        \n",
    "        #  Compute loss\n",
    "        loss = criterion(outputs, masks.long())\n",
    "\n",
    "        #  Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\" Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss / len(dataloader)}\")\n",
    "\n",
    "#  Save the trained model\n",
    "torch.save(model.state_dict(), \"deeplabv3_segmentation.pth\")\n",
    "print(\" Model training complete & saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:27:25.016542Z",
     "iopub.status.busy": "2025-03-28T23:27:25.016250Z",
     "iopub.status.idle": "2025-03-28T23:27:25.229915Z",
     "shell.execute_reply": "2025-03-28T23:27:25.229181Z",
     "shell.execute_reply.started": "2025-03-28T23:27:25.016522Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#  Load the trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeeplabv3_segmentation.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Model loaded for inference!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#  Load the trained model\n",
    "model.load_state_dict(torch.load(\"deeplabv3_segmentation.pth\"))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "print(\" Model loaded for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:27:40.801268Z",
     "iopub.status.busy": "2025-03-28T23:27:40.800966Z",
     "iopub.status.idle": "2025-03-28T23:27:41.758966Z",
     "shell.execute_reply": "2025-03-28T23:27:41.758130Z",
     "shell.execute_reply.started": "2025-03-28T23:27:40.801247Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Pick a test image\n",
    "test_img_path = dataset.image_paths[1]  # Choose any image from dataset\n",
    "test_mask_path = dataset.mask_paths[1]\n",
    "\n",
    "#  Load the image\n",
    "image = Image.open(test_img_path).convert(\"RGB\")\n",
    "image_resized = image.resize((512, 512), Image.BILINEAR)\n",
    "input_tensor = image_transform(image_resized).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "#  Run the model on the image\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)[\"out\"]\n",
    "    predicted_mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()  # Get class with highest probability\n",
    "\n",
    "#  Load ground truth mask\n",
    "ground_truth_mask = Image.open(test_mask_path).resize((512, 512), Image.NEAREST)\n",
    "ground_truth_mask = np.array(ground_truth_mask, dtype=np.uint8)\n",
    "\n",
    "#  Show Image, Prediction, and Ground Truth Mask\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(predicted_mask, cmap=\"jet\")\n",
    "ax[1].set_title(\"Predicted Mask\")\n",
    "ax[2].imshow(ground_truth_mask, cmap=\"jet\")\n",
    "ax[2].set_title(\"Ground Truth Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:27:46.612991Z",
     "iopub.status.busy": "2025-03-28T23:27:46.612633Z",
     "iopub.status.idle": "2025-03-28T23:27:47.308691Z",
     "shell.execute_reply": "2025-03-28T23:27:47.307938Z",
     "shell.execute_reply.started": "2025-03-28T23:27:46.612962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Custom image path\n",
    "test_img_path = '/kaggle/input/semantic-segmentation-of-aerial-imagery/Semantic segmentation dataset/Tile 1/images/image_part_001.jpg'  # Path to your image\n",
    "\n",
    "#  Load the image\n",
    "image = Image.open(test_img_path).convert(\"RGB\")\n",
    "image_resized = image.resize((512, 512), Image.BILINEAR)\n",
    "input_tensor = image_transform(image_resized).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "#  Run the model on the image\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)[\"out\"]\n",
    "    predicted_mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()  # Get class with highest probability\n",
    "\n",
    "#  Show Image and Predicted Mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[1].imshow(predicted_mask, cmap=\"jet\")\n",
    "ax[1].set_title(\"Predicted Mask\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:02.342731Z",
     "iopub.status.busy": "2025-03-28T23:34:02.342411Z",
     "iopub.status.idle": "2025-03-28T23:34:14.197400Z",
     "shell.execute_reply": "2025-03-28T23:34:14.196709Z",
     "shell.execute_reply.started": "2025-03-28T23:34:02.342702Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation, UpSampling2D, \n",
    "                                     AveragePooling2D, Conv2DTranspose, Concatenate, Input)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:19.866695Z",
     "iopub.status.busy": "2025-03-28T23:34:19.866131Z",
     "iopub.status.idle": "2025-03-28T23:34:19.889269Z",
     "shell.execute_reply": "2025-03-28T23:34:19.888421Z",
     "shell.execute_reply.started": "2025-03-28T23:34:19.866662Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/kaggle/input/landslide4sense/TrainData/img/image_1.h5', 'r') as hf:\n",
    "    print(hf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:22.176464Z",
     "iopub.status.busy": "2025-03-28T23:34:22.176120Z",
     "iopub.status.idle": "2025-03-28T23:34:22.190916Z",
     "shell.execute_reply": "2025-03-28T23:34:22.190039Z",
     "shell.execute_reply.started": "2025-03-28T23:34:22.176434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/kaggle/input/landslide4sense/TrainData/mask/mask_10.h5', 'r') as hf1:\n",
    "    print(hf1.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:25.164710Z",
     "iopub.status.busy": "2025-03-28T23:34:25.164404Z",
     "iopub.status.idle": "2025-03-28T23:34:25.886539Z",
     "shell.execute_reply": "2025-03-28T23:34:25.885670Z",
     "shell.execute_reply.started": "2025-03-28T23:34:25.164686Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "path_single = r'/kaggle/input/landslide4sense/TrainData/img/image_1.h5'\n",
    "path_single_mask = r'/kaggle/input/landslide4sense/TrainData/mask/mask_1.h5'\n",
    "\n",
    "f_data = np.zeros((1, 128, 128, 3))\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(path_single, 'r') as hdf:\n",
    "    # Print keys in the HDF5 file\n",
    "    ls = list(hdf.keys())\n",
    "    print(\"Available keys in the HDF5 file:\", ls)\n",
    "    \n",
    "    # Check if 'img' key exists\n",
    "    if 'img' not in ls:\n",
    "        raise KeyError(\"'img' key not found in HDF5 file\")\n",
    "    \n",
    "    # Load the image data\n",
    "    data = np.array(hdf.get('img'))\n",
    "    print(\"Input data shape:\", data.shape)\n",
    "    \n",
    "    # Check the shape to avoid indexing errors\n",
    "    if data.shape[2] < 14:\n",
    "        raise ValueError(\"The data has fewer than 14 channels. Shape:\", data.shape)\n",
    "\n",
    "    # Display a sample image (e.g., Red channel)\n",
    "    plt.imshow(data[:, :, 3])  # Red channel (adjust as needed)\n",
    "    plt.title(\"Red Channel\")\n",
    "    plt.show()\n",
    "\n",
    "    # Extract specific bands for NDVI calculation\n",
    "    data_red = data[:, :, 3]\n",
    "    data_green = data[:, :, 2]\n",
    "    data_blue = data[:, :, 1]\n",
    "    data_nir = data[:, :, 7]\n",
    "\n",
    "    # Calculate NDVI (Normalized Difference Vegetation Index)\n",
    "    data_ndvi = np.divide(data_nir - data_red, np.add(data_nir, data_red), where=(data_nir + data_red) != 0)\n",
    "    \n",
    "    # Store NDVI and other bands in f_data\n",
    "    f_data[0, :, :, 0] = data_ndvi\n",
    "    f_data[0, :, :, 1] = data[:, :, 12]\n",
    "    f_data[0, :, :, 2] = data[:, :, 13]\n",
    "    print(\"data_ndvi shape:\", data_ndvi.shape, \"f_data shape:\", f_data.shape)\n",
    "    \n",
    "    # Plot NDVI\n",
    "    plt.imshow(data_ndvi, cmap='viridis')\n",
    "    plt.title(\"NDVI\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:30.726268Z",
     "iopub.status.busy": "2025-03-28T23:34:30.725980Z",
     "iopub.status.idle": "2025-03-28T23:34:30.919734Z",
     "shell.execute_reply": "2025-03-28T23:34:30.919089Z",
     "shell.execute_reply.started": "2025-03-28T23:34:30.726246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(path_single_mask) as hdf:\n",
    "\n",
    "    ls = list(hdf.keys())\n",
    "\n",
    "    print(\"ls\", ls)\n",
    "\n",
    "    data = np.array(hdf.get('mask'))\n",
    "\n",
    "    print(\"input data shape:\", data.shape)\n",
    "\n",
    "    plt.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:37.685072Z",
     "iopub.status.busy": "2025-03-28T23:34:37.684728Z",
     "iopub.status.idle": "2025-03-28T23:34:37.694718Z",
     "shell.execute_reply": "2025-03-28T23:34:37.693914Z",
     "shell.execute_reply.started": "2025-03-28T23:34:37.685044Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, image_dir, mask_dir, batch_size=1, img_size=(128, 128), shuffle=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # List all the image and mask file names\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "        self.mask_files = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of batches per epoch\n",
    "        return int(np.floor(len(self.image_files) / self.batch_size))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle data at the end of each epoch\n",
    "        if self.shuffle:\n",
    "            temp = list(zip(self.image_files, self.mask_files))\n",
    "            np.random.shuffle(temp)\n",
    "            self.image_files, self.mask_files = zip(*temp)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the list of image and mask files for this batch\n",
    "        batch_images = self.image_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_masks = self.mask_files[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "\n",
    "        # Load and preprocess the images and masks\n",
    "        images = []\n",
    "        masks = []\n",
    "        for img_file, mask_file in zip(batch_images, batch_masks):\n",
    "            img = self.load_image(os.path.join(self.image_dir, img_file))\n",
    "            mask = self.load_mask(os.path.join(self.mask_dir, mask_file))\n",
    "            images.append(img)\n",
    "            masks.append(mask)\n",
    "\n",
    "        # Return as numpy arrays\n",
    "        return np.array(images), np.array(masks)\n",
    "\n",
    "    def load_image(self, img_path):\n",
    "        with h5py.File(img_path, 'r') as hdf:\n",
    "            img_data = np.array(hdf.get('img'))  # (128, 128, 14)\n",
    "            img_data = img_data / 255.0  # Normalize to [0, 1]\n",
    "            return img_data\n",
    "\n",
    "    def load_mask(self, mask_path):\n",
    "        with h5py.File(mask_path, 'r') as hdf:\n",
    "            mask_data = np.array(hdf.get('mask'))  # (128, 128)\n",
    "            mask_data = np.expand_dims(mask_data, axis=-1)  # (128, 128, 1)\n",
    "            return mask_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:41.382885Z",
     "iopub.status.busy": "2025-03-28T23:34:41.382420Z",
     "iopub.status.idle": "2025-03-28T23:34:41.392186Z",
     "shell.execute_reply": "2025-03-28T23:34:41.391193Z",
     "shell.execute_reply.started": "2025-03-28T23:34:41.382844Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n",
    "def ASPP(inputs):\n",
    "    shape = inputs.shape\n",
    "\n",
    "    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n",
    "    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n",
    "    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n",
    "    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n",
    "    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n",
    "\n",
    "    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n",
    "    y_1 = BatchNormalization()(y_1)\n",
    "    y_1 = Activation('relu')(y_1)\n",
    "\n",
    "    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n",
    "    y_6 = BatchNormalization()(y_6)\n",
    "    y_6 = Activation('relu')(y_6)\n",
    "\n",
    "    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n",
    "    y_12 = BatchNormalization()(y_12)\n",
    "    y_12 = Activation('relu')(y_12)\n",
    "\n",
    "    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n",
    "    y_18 = BatchNormalization()(y_18)\n",
    "    y_18 = Activation('relu')(y_18)\n",
    "\n",
    "    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n",
    "\n",
    "    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:44.478496Z",
     "iopub.status.busy": "2025-03-28T23:34:44.478184Z",
     "iopub.status.idle": "2025-03-28T23:34:44.484814Z",
     "shell.execute_reply": "2025-03-28T23:34:44.483901Z",
     "shell.execute_reply.started": "2025-03-28T23:34:44.478473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def DeepLabV3Plus(shape):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = Input(shape)\n",
    "\n",
    "    \"\"\" Pre-trained ResNet50 \"\"\"\n",
    "    base_model = ResNet50(weights=None, include_top=False, input_tensor=inputs)\n",
    "\n",
    "    \"\"\" Pre-trained ResNet50 Output \"\"\"\n",
    "    image_features = base_model.get_layer('conv4_block6_out').output\n",
    "    x_a = ASPP(image_features)\n",
    "    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n",
    "\n",
    "    \"\"\" Get low-level features \"\"\"\n",
    "    x_b = base_model.get_layer('conv2_block2_out').output\n",
    "    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n",
    "    x_b = BatchNormalization()(x_b)\n",
    "    x_b = Activation('relu')(x_b)\n",
    "\n",
    "    x = Concatenate()([x_a, x_b])\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n",
    "\n",
    "    \"\"\" Outputs \"\"\"\n",
    "    x = Conv2D(1, (1, 1), name='output_layer')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = Model(inputs=inputs, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:47.174094Z",
     "iopub.status.busy": "2025-03-28T23:34:47.173782Z",
     "iopub.status.idle": "2025-03-28T23:34:47.179279Z",
     "shell.execute_reply": "2025-03-28T23:34:47.178450Z",
     "shell.execute_reply.started": "2025-03-28T23:34:47.174070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = K.cast(y_true, dtype='float32')  # Ensure both are float32\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.flatten(y_true_f)  # Flatten after conversion\n",
    "\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:50.861707Z",
     "iopub.status.busy": "2025-03-28T23:34:50.861363Z",
     "iopub.status.idle": "2025-03-28T23:34:51.052488Z",
     "shell.execute_reply": "2025-03-28T23:34:51.051617Z",
     "shell.execute_reply.started": "2025-03-28T23:34:50.861678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(\n",
    "    image_dir='/kaggle/input/landslide4sense/TrainData/img',\n",
    "    mask_dir='/kaggle/input/landslide4sense/TrainData/mask',\n",
    "    batch_size=32,  # Adjust based on memory\n",
    "    img_size=(128, 128),  # Match your input data\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:34:53.233415Z",
     "iopub.status.busy": "2025-03-28T23:34:53.233129Z",
     "iopub.status.idle": "2025-03-28T23:34:57.261887Z",
     "shell.execute_reply": "2025-03-28T23:34:57.261008Z",
     "shell.execute_reply.started": "2025-03-28T23:34:53.233392Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "input_shape = (128, 128, 14)\n",
    "with strategy.scope():\n",
    "    model = DeepLabV3Plus(input_shape)\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), \n",
    "                  loss=dice_loss, \n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:35:09.997877Z",
     "iopub.status.busy": "2025-03-28T23:35:09.997560Z",
     "iopub.status.idle": "2025-03-29T00:10:09.686219Z",
     "shell.execute_reply": "2025-03-29T00:10:09.685284Z",
     "shell.execute_reply.started": "2025-03-28T23:35:09.997852Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:05:44.822739Z",
     "iopub.status.busy": "2025-03-28T23:05:44.822427Z",
     "iopub.status.idle": "2025-03-28T23:05:45.849552Z",
     "shell.execute_reply": "2025-03-28T23:05:45.848606Z",
     "shell.execute_reply.started": "2025-03-28T23:05:44.822700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save(\"deeplabv3_landslide.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T00:10:09.688171Z",
     "iopub.status.busy": "2025-03-29T00:10:09.687931Z",
     "iopub.status.idle": "2025-03-29T00:10:10.488063Z",
     "shell.execute_reply": "2025-03-29T00:10:10.487174Z",
     "shell.execute_reply.started": "2025-03-29T00:10:09.688149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('deeplabv3_landslide_keras.h5')  # Save model in Keras .h5 format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:14:55.994375Z",
     "iopub.status.busy": "2025-03-28T23:14:55.994065Z",
     "iopub.status.idle": "2025-03-28T23:14:57.071112Z",
     "shell.execute_reply": "2025-03-28T23:14:57.070001Z",
     "shell.execute_reply.started": "2025-03-28T23:14:55.994349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Load the pre-trained model without compilation or custom objects\n",
    "model = tf.keras.models.load_model('/kaggle/working/deeplabv3_landslide_keras.h5', compile=False)\n",
    "\n",
    "# Load images from HDF5\n",
    "def load_images_from_h5(file_path, dataset_name='img'):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        images = np.array(f[dataset_name])  # Load images from the specified dataset\n",
    "        print(\"Images shape:\", images.shape)\n",
    "    return images\n",
    "\n",
    "image_file_path = '/kaggle/input/landslide4sense/TrainData/img/image_10.h5'  # Path to H5 file containing images\n",
    "images = load_images_from_h5(image_file_path)\n",
    "\n",
    "# Preprocess the images (resize, normalize)\n",
    "images_resized = tf.image.resize(images, (128, 128)) / 255.0  # Adjust size and normalization\n",
    "\n",
    "# Perform inference\n",
    "predictions = model.predict(images_resized)\n",
    "\n",
    "# Visualize a sample result (the predicted mask for the first image)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(images_resized[0])  # Display original image\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predictions[0], cmap='jet')  # Display predicted segmentation mask\n",
    "plt.title('Predicted Mask')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T23:17:05.178145Z",
     "iopub.status.busy": "2025-03-28T23:17:05.177722Z",
     "iopub.status.idle": "2025-03-28T23:17:08.957122Z",
     "shell.execute_reply": "2025-03-28T23:17:08.956231Z",
     "shell.execute_reply.started": "2025-03-28T23:17:05.178113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Load the pre-trained model without compilation or custom objects\n",
    "model = tf.keras.models.load_model('/kaggle/working/deeplabv3_landslide_keras.h5', compile=False)\n",
    "\n",
    "# Load images from HDF5\n",
    "def load_images_from_h5(file_path, dataset_name='img'):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        images = np.array(f[dataset_name])  # Load images from the specified dataset\n",
    "        print(\"Images shape:\", images.shape)\n",
    "    return images\n",
    "\n",
    "image_file_path = '/kaggle/input/landslide4sense/TrainData/img/image_10.h5'  # Path to H5 file containing images\n",
    "images = load_images_from_h5(image_file_path)\n",
    "\n",
    "# Preprocess the images (resize, normalize)\n",
    "images_resized = tf.image.resize(images, (128, 128)) / 255.0  # Adjust size and normalization\n",
    "\n",
    "# Add the batch dimension (None, 128, 128, 14)\n",
    "images_resized = np.expand_dims(images_resized, axis=0)  # This adds the batch dimension\n",
    "\n",
    "# Perform inference\n",
    "predictions = model.predict(images_resized)\n",
    "\n",
    "# Visualize a sample result\n",
    "# Visualize the first channel (e.g., the first channel in the image)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(images_resized[0, :, :, 0], cmap='gray')  # Display the first channel\n",
    "plt.title('Original Image - Channel 0')\n",
    "\n",
    "# If the output is a multi-class prediction, choose the most probable class\n",
    "predicted_mask = predictions[0]  # Get the first image's prediction\n",
    "predicted_mask_class = np.argmax(predicted_mask, axis=-1)  # Get the most probable class\n",
    "\n",
    "# Visualize the predicted segmentation mask\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(predicted_mask_class, cmap='jet')  # Display predicted segmentation mask\n",
    "plt.title('Predicted Mask')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T00:10:56.822004Z",
     "iopub.status.busy": "2025-03-29T00:10:56.821660Z",
     "iopub.status.idle": "2025-03-29T00:11:00.965053Z",
     "shell.execute_reply": "2025-03-29T00:11:00.964115Z",
     "shell.execute_reply.started": "2025-03-29T00:10:56.821974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Path to the trained model\n",
    "model_path = 'deeplabv3_landslide_keras.h5'\n",
    "# Path to the input image for inference\n",
    "input_image_path = '/kaggle/input/landslide4sense/TrainData/img/image_101.h5'\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(model_path, custom_objects={'dice_loss': dice_loss, 'dice_coefficient': dice_coefficient})\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(image_path, img_size=(128, 128)):\n",
    "    with h5py.File(image_path, 'r') as hdf:\n",
    "        img_data = np.array(hdf.get('img'))  # Shape (128, 128, 14)\n",
    "        \n",
    "        # Normalize image data (same as done during training)\n",
    "        img_data = img_data / 255.0  # Normalize to [0, 1]\n",
    "        \n",
    "        # Resize the image (if necessary) to match input size\n",
    "        if img_data.shape[:2] != img_size:\n",
    "            img_data = np.resize(img_data, (*img_size, img_data.shape[2]))\n",
    "        \n",
    "        return img_data\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = load_and_preprocess_image(input_image_path)\n",
    "\n",
    "# Expand dimensions to match the model's input (batch size, height, width, channels)\n",
    "image_input = np.expand_dims(image, axis=0)  # Shape becomes (1, 128, 128, 14)\n",
    "\n",
    "# Run the model for prediction\n",
    "prediction = model.predict(image_input)\n",
    "\n",
    "# Get the predicted mask (for binary segmentation, threshold the output)\n",
    "predicted_mask = (prediction > 0.5).astype(np.uint8)  # Apply threshold\n",
    "\n",
    "# Plot the original image and the predicted mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Show original image (for visual inspection)\n",
    "ax[0].imshow(image[:, :, 0], cmap='viridis')  # Show the first channel (e.g., NDVI)\n",
    "ax[0].set_title('Original Image (First Channel)')\n",
    "\n",
    "# Show predicted mask\n",
    "ax[1].imshow(predicted_mask[0, :, :, 0], cmap='jet')  # Predicted mask for the first image in the batch\n",
    "ax[1].set_title('Predicted Mask')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 681625,
     "sourceId": 1196732,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4160916,
     "sourceId": 7194910,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6992407,
     "sourceId": 11199372,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6992579,
     "sourceId": 11199611,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
