{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6wbe8aVvGm",
        "outputId": "9b14ed23-b6d6-45ce-8179-daf4c9ae11f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar 29 21:31:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGEiepRyUGb",
        "outputId": "777d2682-12bf-47c9-bb74-710fe8692592"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedViT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cd /content/MedViT\n",
        "import os\n",
        "os.chdir('/content/MedViT')\n",
        ""
      ],
      "metadata": {
        "id": "s-YP2dhcyaI7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "CYM5Kymzywf7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN--gKiey2lU",
        "outputId": "1e3ef836-ea2d-4838-c10d-11c920c4ae74"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sliYqkhRy4z6",
        "outputId": "748e6717-dcf9-4ec4-877e-cfa625b1f5f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhbsqKgZzTnm",
        "outputId": "4c650364-0ec2-4a1d-986f-c5975c4510e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPgfoXTwzY1s",
        "outputId": "c35a5447-7b0e-491f-f2bb-79acf2ce5b93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)"
      ],
      "metadata": {
        "id": "s0UXgCflzcgE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "JpVjgdg5zfg6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AssLrMPYzjfd",
        "outputId": "058be950-0a98-4625-cbaa-ad8831e5b376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.1.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "s6OOvD28zmE7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'breastmnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        ""
      ],
      "metadata": {
        "id": "bBOVL7b_zzQC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        ""
      ],
      "metadata": {
        "id": "gMFeTC8_z3lK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npDi-1s3z7Ty",
        "outputId": "83d97099-ce7c-47f0-d8b2-8842957ba966"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 546\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1√ó500√ó500 are resized into 1√ó28√ó28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 156\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1√ó500√ó500 are resized into 1√ó28√ó28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "yCk8YZUxz8pb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmeyPuzg0CZz",
        "outputId": "3d9ede86-dd96-49c3-d72f-0550536ab519"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:22<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:19<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:20<00:00,  2.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9WiDlHp0opj",
        "outputId": "6221ef45-6ab5-4137-faa7-893df9c5ccaf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 0.916  acc:0.826\n",
            "test  auc: 0.873  acc:0.827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch2keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-54Aspi13cR",
        "outputId": "8947f83f-e338-4539-81c9-1d82e719c4c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch2keras (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch2keras\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Model saved as model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8a7SVZ_2DF6",
        "outputId": "bb26b55f-5a99-4e73-bcbf-5487b69861bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Manually adjust the output layer to match saved model\n",
        "model.proj_head[0] = torch.nn.Linear(1024, 2)  # Match shape from checkpoint\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.cuda()\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfud6QOp2v5x",
        "outputId": "6f0b2648-c01e-4c73-fd18-33645558eb2f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from medmnist import INFO\n",
        "from medmnist.dataset import BreastMNIST  # Import the correct dataset class\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Define dataset parameters\n",
        "DATASET_NAME = \"breastmnist\"\n",
        "info = INFO[DATASET_NAME]\n",
        "num_classes = len(info[\"label\"])\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Adjust the output layer to match MedMNIST classes\n",
        "model.proj_head[0] = torch.nn.Linear(1024, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n",
        "\n",
        "# Define image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size if needed\n",
        "    transforms.Grayscale(3),  # Convert to 3-channel if needed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load BreastMNIST dataset\n",
        "test_dataset = BreastMNIST(split=\"test\", download=True)  # Use specific dataset class\n",
        "\n",
        "# Function to perform inference\n",
        "def predict_medmnist(index):\n",
        "    image, label = test_dataset[index]  # Get an image from the dataset\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Apply transforms and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()  # Get highest probability class\n",
        "\n",
        "    return predicted_class, label  # Return both predicted and actual class\n",
        "\n",
        "# Example usage\n",
        "index = 0  # Choose an index from the test dataset\n",
        "predicted_class, actual_class = predict_medmnist(index)\n",
        "print(f\"Predicted class: {predicted_class}, Actual class: {actual_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgzQL3ZV3iEf",
        "outputId": "1794e24a-4f4b-43d3-f73d-5b3563d9ca6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n",
            "Predicted class: 0, Actual class: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from medmnist import INFO\n",
        "from medmnist.dataset import BreastMNIST  # Import the correct dataset class\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Define dataset parameters\n",
        "DATASET_NAME = \"breastmnist\"\n",
        "info = INFO[DATASET_NAME]\n",
        "num_classes = len(info[\"label\"])\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Adjust the output layer to match MedMNIST classes\n",
        "model.proj_head[0] = torch.nn.Linear(1024, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n",
        "\n",
        "# Define image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size if needed\n",
        "    transforms.Grayscale(3),  # Convert to 3-channel if needed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load BreastMNIST dataset\n",
        "test_dataset = BreastMNIST(split=\"test\", download=True)  # Use specific dataset class\n",
        "\n",
        "# Function to perform inference\n",
        "def predict_medmnist(index):\n",
        "    image, label = test_dataset[index]  # Get an image from the dataset\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Apply transforms and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()  # Get highest probability class\n",
        "\n",
        "    return predicted_class, label  # Return both predicted and actual class\n",
        "\n",
        "# Make predictions for multiple images (Example: first 10 images in the test set)\n",
        "num_predictions = 50  # Set the number of images you want to predict\n",
        "for index in range(num_predictions):\n",
        "    predicted_class, actual_class = predict_medmnist(index)\n",
        "    print(f\"Image Index {index}: Predicted class: {predicted_class}, Actual class: {actual_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC-b_SzS391f",
        "outputId": "6d03640b-89de-409d-e3d7-a7128587f60e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n",
            "Image Index 0: Predicted class: 0, Actual class: [0]\n",
            "Image Index 1: Predicted class: 1, Actual class: [1]\n",
            "Image Index 2: Predicted class: 0, Actual class: [1]\n",
            "Image Index 3: Predicted class: 0, Actual class: [1]\n",
            "Image Index 4: Predicted class: 0, Actual class: [1]\n",
            "Image Index 5: Predicted class: 0, Actual class: [1]\n",
            "Image Index 6: Predicted class: 0, Actual class: [0]\n",
            "Image Index 7: Predicted class: 0, Actual class: [0]\n",
            "Image Index 8: Predicted class: 0, Actual class: [1]\n",
            "Image Index 9: Predicted class: 0, Actual class: [1]\n",
            "Image Index 10: Predicted class: 0, Actual class: [0]\n",
            "Image Index 11: Predicted class: 0, Actual class: [0]\n",
            "Image Index 12: Predicted class: 0, Actual class: [1]\n",
            "Image Index 13: Predicted class: 0, Actual class: [0]\n",
            "Image Index 14: Predicted class: 0, Actual class: [1]\n",
            "Image Index 15: Predicted class: 0, Actual class: [0]\n",
            "Image Index 16: Predicted class: 0, Actual class: [1]\n",
            "Image Index 17: Predicted class: 0, Actual class: [1]\n",
            "Image Index 18: Predicted class: 0, Actual class: [1]\n",
            "Image Index 19: Predicted class: 0, Actual class: [1]\n",
            "Image Index 20: Predicted class: 0, Actual class: [0]\n",
            "Image Index 21: Predicted class: 0, Actual class: [1]\n",
            "Image Index 22: Predicted class: 0, Actual class: [1]\n",
            "Image Index 23: Predicted class: 0, Actual class: [0]\n",
            "Image Index 24: Predicted class: 0, Actual class: [0]\n",
            "Image Index 25: Predicted class: 0, Actual class: [1]\n",
            "Image Index 26: Predicted class: 0, Actual class: [0]\n",
            "Image Index 27: Predicted class: 0, Actual class: [1]\n",
            "Image Index 28: Predicted class: 0, Actual class: [1]\n",
            "Image Index 29: Predicted class: 0, Actual class: [1]\n",
            "Image Index 30: Predicted class: 0, Actual class: [1]\n",
            "Image Index 31: Predicted class: 0, Actual class: [1]\n",
            "Image Index 32: Predicted class: 0, Actual class: [1]\n",
            "Image Index 33: Predicted class: 0, Actual class: [1]\n",
            "Image Index 34: Predicted class: 0, Actual class: [1]\n",
            "Image Index 35: Predicted class: 0, Actual class: [0]\n",
            "Image Index 36: Predicted class: 0, Actual class: [1]\n",
            "Image Index 37: Predicted class: 0, Actual class: [1]\n",
            "Image Index 38: Predicted class: 0, Actual class: [0]\n",
            "Image Index 39: Predicted class: 0, Actual class: [1]\n",
            "Image Index 40: Predicted class: 0, Actual class: [0]\n",
            "Image Index 41: Predicted class: 0, Actual class: [1]\n",
            "Image Index 42: Predicted class: 0, Actual class: [0]\n",
            "Image Index 43: Predicted class: 0, Actual class: [1]\n",
            "Image Index 44: Predicted class: 0, Actual class: [0]\n",
            "Image Index 45: Predicted class: 0, Actual class: [0]\n",
            "Image Index 46: Predicted class: 0, Actual class: [1]\n",
            "Image Index 47: Predicted class: 0, Actual class: [1]\n",
            "Image Index 48: Predicted class: 0, Actual class: [0]\n",
            "Image Index 49: Predicted class: 0, Actual class: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "from torch.utils.data import DataLoader\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the dataset\n",
        "data_flag = 'breastmnist'\n",
        "\n",
        "# Get dataset info\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Get the dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Define test dataset transformations\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Process one sample at a time\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load trained model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Perform inference on the entire dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(\"üîç Inference Results:\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        # Forward pass (Inference)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Convert logits to class predictions\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Compare prediction with ground truth\n",
        "        is_correct = predicted.item() == targets.item()\n",
        "        correct += is_correct\n",
        "        total += 1\n",
        "\n",
        "        # Print each prediction\n",
        "        print(f\"üñº Sample {i+1}: Predicted = {predicted.item()}, Actual = {targets.item()}, {'‚úÖ' if is_correct else '‚ùå'}\")\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"\\nüéØ Model Accuracy: {accuracy:.2f}% on BreastMNIST test set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YdBkXwm_gZr",
        "outputId": "3ca1cf8c-4093-43b5-9b0e-fde06b08aaf6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "üîç Inference Results:\n",
            "üñº Sample 1: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 2: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 3: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 4: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 5: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 6: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 7: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 8: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 9: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 10: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 11: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 12: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 13: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 14: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 15: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 16: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 17: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 18: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 19: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 20: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 21: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 22: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 23: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 24: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 25: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 26: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 27: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 28: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 29: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 30: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 31: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 32: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 33: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 34: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 35: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 36: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 37: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 38: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 39: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 40: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 41: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 42: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 43: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 44: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 45: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 46: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 47: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 48: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 49: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 50: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 51: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 52: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 53: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 54: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 55: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 56: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 57: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 58: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 59: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 60: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 61: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 62: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 63: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 64: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 65: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 66: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 67: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 68: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 69: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 70: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 71: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 72: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 73: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 74: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 75: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 76: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 77: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 78: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 79: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 80: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 81: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 82: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 83: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 84: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 85: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 86: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 87: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 88: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 89: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 90: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 91: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 92: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 93: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 94: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 95: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 96: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 97: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 98: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 99: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 100: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 101: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 102: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 103: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 104: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 105: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 106: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 107: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 108: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 109: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 110: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 111: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 112: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 113: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 114: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 115: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 116: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 117: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 118: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 119: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 120: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 121: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 122: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 123: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 124: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 125: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 126: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 127: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 128: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 129: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 130: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 131: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 132: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 133: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 134: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 135: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 136: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 137: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 138: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 139: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 140: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 141: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 142: Predicted = 1, Actual = 0, ‚ùå\n",
            "üñº Sample 143: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 144: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 145: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 146: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 147: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 148: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 149: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 150: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 151: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 152: Predicted = 0, Actual = 1, ‚ùå\n",
            "üñº Sample 153: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 154: Predicted = 0, Actual = 0, ‚úÖ\n",
            "üñº Sample 155: Predicted = 1, Actual = 1, ‚úÖ\n",
            "üñº Sample 156: Predicted = 1, Actual = 1, ‚úÖ\n",
            "\n",
            "üéØ Model Accuracy: 82.69% on BreastMNIST test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the data flag\n",
        "data_flag = 'breastmnist'  # Dataset used\n",
        "\n",
        "# Load info for the dataset\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Define the MedMNIST dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Preprocessing transformation for the dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),  # Convert to RGB if necessary\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Single sample inference\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load the trained weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function for inference\n",
        "def inference(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs = inputs.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # If the task is binary classification or multi-class classification\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the index of the class with the highest score\n",
        "\n",
        "            # Convert prediction and target to CPU for visualization or analysis\n",
        "            predicted_class = predicted.item()\n",
        "            true_class = targets.item()\n",
        "\n",
        "            print(f\"True Class: {true_class}, Predicted Class: {predicted_class}\")\n",
        "            return predicted_class, true_class  # You can return the prediction for further analysis\n",
        "\n",
        "# Perform inference on a single batch from the test dataset\n",
        "inference(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBJXbesl6G1e",
        "outputId": "69d0c111-d1b2-4ecb-e402-80c96b1e7572"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "True Class: 0, Predicted Class: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "from torch.utils.data import DataLoader\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the data flag\n",
        "data_flag = 'breastmnist'  # Dataset used\n",
        "\n",
        "# Load info for the dataset\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Define the MedMNIST dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Preprocessing transformation for the dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),  # Convert to RGB if necessary\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Process multiple samples at once\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load the trained weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function for inference on the entire dataset\n",
        "def inference_on_all_samples(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # For multi-class classification, get the class with the highest score\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_true.extend(targets.cpu().numpy())\n",
        "\n",
        "    return all_true, all_preds\n",
        "\n",
        "# Perform inference on the entire test dataset\n",
        "true_labels, predicted_labels = inference_on_all_samples(model, test_loader)\n",
        "\n",
        "# You can then compare the true and predicted labels\n",
        "correct = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "accuracy = correct / len(true_labels)\n",
        "\n",
        "print(f\"Accuracy on the entire test set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0P-D1e6UsG",
        "outputId": "a09428e0-e2e5-44db-d8df-82d36e8503c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Accuracy on the entire test set: 82.69%\n"
          ]
        }
      ]
    }
  ]
}