{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6wbe8aVvGm",
        "outputId": "9b14ed23-b6d6-45ce-8179-daf4c9ae11f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Mar 29 21:31:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Omid-Nejati/MedViT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FGEiepRyUGb",
        "outputId": "777d2682-12bf-47c9-bb74-710fe8692592"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'MedViT' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cd /content/MedViT\n",
        "import os\n",
        "os.chdir('/content/MedViT')\n",
        ""
      ],
      "metadata": {
        "id": "s-YP2dhcyaI7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "CYM5Kymzywf7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm\n",
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN--gKiey2lU",
        "outputId": "1e3ef836-ea2d-4838-c10d-11c920c4ae74"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from MedViT import MedViT_small as tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sliYqkhRy4z6",
        "outputId": "748e6717-dcf9-4ec4-877e-cfa625b1f5f2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tiny()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhbsqKgZzTnm",
        "outputId": "4c650364-0ec2-4a1d-986f-c5975c4510e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPgfoXTwzY1s",
        "outputId": "c35a5447-7b0e-491f-f2bb-79acf2ce5b93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1024, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)"
      ],
      "metadata": {
        "id": "s0UXgCflzcgE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "JpVjgdg5zfg6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install medmnist\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AssLrMPYzjfd",
        "outputId": "058be950-0a98-4625-cbaa-ad8831e5b376"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: medmnist in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist) (11.1.0)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist) (0.21.0+cu124)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (2025.3.13)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (4.12.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator"
      ],
      "metadata": {
        "id": "s6OOvD28zmE7"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'breastmnist'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 10\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        ""
      ],
      "metadata": {
        "id": "bBOVL7b_zzQC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    torchvision.transforms.AugMix(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# load the data\n",
        "train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        ""
      ],
      "metadata": {
        "id": "gMFeTC8_z3lK"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npDi-1s3z7Ty",
        "outputId": "83d97099-ce7c-47f0-d8b2-8842957ba966"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 546\n",
            "    Root location: /root/.medmnist\n",
            "    Split: train\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n",
            "===================\n",
            "Dataset BreastMNIST of size 28 (breastmnist)\n",
            "    Number of datapoints: 156\n",
            "    Root location: /root/.medmnist\n",
            "    Split: test\n",
            "    Task: binary-class\n",
            "    Number of channels: 1\n",
            "    Meaning of labels: {'0': 'malignant', '1': 'normal, benign'}\n",
            "    Number of samples: {'train': 546, 'val': 78, 'test': 156}\n",
            "    Description: The BreastMNIST is based on a dataset of 780 breast ultrasound images. It is categorized into 3 classes: normal, benign, and malignant. As we use low-resolution images, we simplify the task into binary classification by combining normal and benign as positive and classifying them against malignant as negative. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. The source images of 1×500×500 are resized into 1×28×28.\n",
            "    License: CC BY 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss function and optimizer\n",
        "if task == \"multi-label, binary-class\":\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ],
      "metadata": {
        "id": "yCk8YZUxz8pb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    print('Epoch [%d/%d]'% (epoch+1, NUM_EPOCHS))\n",
        "    model.train()\n",
        "    for inputs, targets in tqdm(train_loader):\n",
        "        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        # forward + backward + optimize\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        if task == 'multi-label, binary-class':\n",
        "            targets = targets.to(torch.float32)\n",
        "            loss = criterion(outputs, targets)\n",
        "        else:\n",
        "            targets = targets.squeeze().long()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmeyPuzg0CZz",
        "outputId": "3d9ede86-dd96-49c3-d72f-0550536ab519"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:22<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:19<00:00,  2.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 55/55 [00:20<00:00,  2.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation\n",
        "\n",
        "def test(split):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).cuda()\n",
        "    y_score = torch.tensor([]).cuda()\n",
        "\n",
        "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        evaluator = Evaluator(data_flag, split)\n",
        "        metrics = evaluator.evaluate(y_score)\n",
        "\n",
        "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "\n",
        "\n",
        "print('==> Evaluating ...')\n",
        "test('train')\n",
        "test('test')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9WiDlHp0opj",
        "outputId": "6221ef45-6ab5-4137-faa7-893df9c5ccaf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Evaluating ...\n",
            "train  auc: 0.916  acc:0.826\n",
            "test  auc: 0.873  acc:0.827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch2keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-54Aspi13cR",
        "outputId": "8947f83f-e338-4539-81c9-1d82e719c4c2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch2keras (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch2keras\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Model saved as model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8a7SVZ_2DF6",
        "outputId": "bb26b55f-5a99-4e73-bcbf-5487b69861bb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Manually adjust the output layer to match saved model\n",
        "model.proj_head[0] = torch.nn.Linear(1024, 2)  # Match shape from checkpoint\n",
        "\n",
        "# Move model to GPU if available\n",
        "model = model.cuda()\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rfud6QOp2v5x",
        "outputId": "6f0b2648-c01e-4c73-fd18-33645558eb2f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from medmnist import INFO\n",
        "from medmnist.dataset import BreastMNIST  # Import the correct dataset class\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Define dataset parameters\n",
        "DATASET_NAME = \"breastmnist\"\n",
        "info = INFO[DATASET_NAME]\n",
        "num_classes = len(info[\"label\"])\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Adjust the output layer to match MedMNIST classes\n",
        "model.proj_head[0] = torch.nn.Linear(1024, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n",
        "\n",
        "# Define image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size if needed\n",
        "    transforms.Grayscale(3),  # Convert to 3-channel if needed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load BreastMNIST dataset\n",
        "test_dataset = BreastMNIST(split=\"test\", download=True)  # Use specific dataset class\n",
        "\n",
        "# Function to perform inference\n",
        "def predict_medmnist(index):\n",
        "    image, label = test_dataset[index]  # Get an image from the dataset\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Apply transforms and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()  # Get highest probability class\n",
        "\n",
        "    return predicted_class, label  # Return both predicted and actual class\n",
        "\n",
        "# Example usage\n",
        "index = 0  # Choose an index from the test dataset\n",
        "predicted_class, actual_class = predict_medmnist(index)\n",
        "print(f\"Predicted class: {predicted_class}, Actual class: {actual_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgzQL3ZV3iEf",
        "outputId": "1794e24a-4f4b-43d3-f73d-5b3563d9ca6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n",
            "Predicted class: 0, Actual class: [0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from medmnist import INFO\n",
        "from medmnist.dataset import BreastMNIST  # Import the correct dataset class\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small\n",
        "\n",
        "# Define dataset parameters\n",
        "DATASET_NAME = \"breastmnist\"\n",
        "info = INFO[DATASET_NAME]\n",
        "num_classes = len(info[\"label\"])\n",
        "\n",
        "# Initialize model\n",
        "model = MedViT_small()\n",
        "\n",
        "# Adjust the output layer to match MedMNIST classes\n",
        "model.proj_head[0] = torch.nn.Linear(1024, num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Load model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully from model.pth\")\n",
        "\n",
        "# Define image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Adjust size if needed\n",
        "    transforms.Grayscale(3),  # Convert to 3-channel if needed\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load BreastMNIST dataset\n",
        "test_dataset = BreastMNIST(split=\"test\", download=True)  # Use specific dataset class\n",
        "\n",
        "# Function to perform inference\n",
        "def predict_medmnist(index):\n",
        "    image, label = test_dataset[index]  # Get an image from the dataset\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Apply transforms and add batch dimension\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        predicted_class = torch.argmax(output, dim=1).item()  # Get highest probability class\n",
        "\n",
        "    return predicted_class, label  # Return both predicted and actual class\n",
        "\n",
        "# Make predictions for multiple images (Example: first 10 images in the test set)\n",
        "num_predictions = 50  # Set the number of images you want to predict\n",
        "for index in range(num_predictions):\n",
        "    predicted_class, actual_class = predict_medmnist(index)\n",
        "    print(f\"Image Index {index}: Predicted class: {predicted_class}, Actual class: {actual_class}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC-b_SzS391f",
        "outputId": "6d03640b-89de-409d-e3d7-a7128587f60e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Model loaded successfully from model.pth\n",
            "Image Index 0: Predicted class: 0, Actual class: [0]\n",
            "Image Index 1: Predicted class: 1, Actual class: [1]\n",
            "Image Index 2: Predicted class: 0, Actual class: [1]\n",
            "Image Index 3: Predicted class: 0, Actual class: [1]\n",
            "Image Index 4: Predicted class: 0, Actual class: [1]\n",
            "Image Index 5: Predicted class: 0, Actual class: [1]\n",
            "Image Index 6: Predicted class: 0, Actual class: [0]\n",
            "Image Index 7: Predicted class: 0, Actual class: [0]\n",
            "Image Index 8: Predicted class: 0, Actual class: [1]\n",
            "Image Index 9: Predicted class: 0, Actual class: [1]\n",
            "Image Index 10: Predicted class: 0, Actual class: [0]\n",
            "Image Index 11: Predicted class: 0, Actual class: [0]\n",
            "Image Index 12: Predicted class: 0, Actual class: [1]\n",
            "Image Index 13: Predicted class: 0, Actual class: [0]\n",
            "Image Index 14: Predicted class: 0, Actual class: [1]\n",
            "Image Index 15: Predicted class: 0, Actual class: [0]\n",
            "Image Index 16: Predicted class: 0, Actual class: [1]\n",
            "Image Index 17: Predicted class: 0, Actual class: [1]\n",
            "Image Index 18: Predicted class: 0, Actual class: [1]\n",
            "Image Index 19: Predicted class: 0, Actual class: [1]\n",
            "Image Index 20: Predicted class: 0, Actual class: [0]\n",
            "Image Index 21: Predicted class: 0, Actual class: [1]\n",
            "Image Index 22: Predicted class: 0, Actual class: [1]\n",
            "Image Index 23: Predicted class: 0, Actual class: [0]\n",
            "Image Index 24: Predicted class: 0, Actual class: [0]\n",
            "Image Index 25: Predicted class: 0, Actual class: [1]\n",
            "Image Index 26: Predicted class: 0, Actual class: [0]\n",
            "Image Index 27: Predicted class: 0, Actual class: [1]\n",
            "Image Index 28: Predicted class: 0, Actual class: [1]\n",
            "Image Index 29: Predicted class: 0, Actual class: [1]\n",
            "Image Index 30: Predicted class: 0, Actual class: [1]\n",
            "Image Index 31: Predicted class: 0, Actual class: [1]\n",
            "Image Index 32: Predicted class: 0, Actual class: [1]\n",
            "Image Index 33: Predicted class: 0, Actual class: [1]\n",
            "Image Index 34: Predicted class: 0, Actual class: [1]\n",
            "Image Index 35: Predicted class: 0, Actual class: [0]\n",
            "Image Index 36: Predicted class: 0, Actual class: [1]\n",
            "Image Index 37: Predicted class: 0, Actual class: [1]\n",
            "Image Index 38: Predicted class: 0, Actual class: [0]\n",
            "Image Index 39: Predicted class: 0, Actual class: [1]\n",
            "Image Index 40: Predicted class: 0, Actual class: [0]\n",
            "Image Index 41: Predicted class: 0, Actual class: [1]\n",
            "Image Index 42: Predicted class: 0, Actual class: [0]\n",
            "Image Index 43: Predicted class: 0, Actual class: [1]\n",
            "Image Index 44: Predicted class: 0, Actual class: [0]\n",
            "Image Index 45: Predicted class: 0, Actual class: [0]\n",
            "Image Index 46: Predicted class: 0, Actual class: [1]\n",
            "Image Index 47: Predicted class: 0, Actual class: [1]\n",
            "Image Index 48: Predicted class: 0, Actual class: [0]\n",
            "Image Index 49: Predicted class: 0, Actual class: [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "from torch.utils.data import DataLoader\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the dataset\n",
        "data_flag = 'breastmnist'\n",
        "\n",
        "# Get dataset info\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Get the dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Define test dataset transformations\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Process one sample at a time\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load trained model weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Perform inference on the entire dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "print(\"🔍 Inference Results:\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, targets) in enumerate(test_loader):\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        # Forward pass (Inference)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Convert logits to class predictions\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Compare prediction with ground truth\n",
        "        is_correct = predicted.item() == targets.item()\n",
        "        correct += is_correct\n",
        "        total += 1\n",
        "\n",
        "        # Print each prediction\n",
        "        print(f\"🖼 Sample {i+1}: Predicted = {predicted.item()}, Actual = {targets.item()}, {'✅' if is_correct else '❌'}\")\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"\\n🎯 Model Accuracy: {accuracy:.2f}% on BreastMNIST test set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YdBkXwm_gZr",
        "outputId": "3ca1cf8c-4093-43b5-9b0e-fde06b08aaf6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "🔍 Inference Results:\n",
            "🖼 Sample 1: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 2: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 3: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 4: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 5: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 6: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 7: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 8: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 9: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 10: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 11: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 12: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 13: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 14: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 15: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 16: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 17: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 18: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 19: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 20: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 21: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 22: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 23: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 24: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 25: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 26: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 27: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 28: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 29: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 30: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 31: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 32: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 33: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 34: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 35: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 36: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 37: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 38: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 39: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 40: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 41: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 42: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 43: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 44: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 45: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 46: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 47: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 48: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 49: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 50: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 51: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 52: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 53: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 54: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 55: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 56: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 57: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 58: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 59: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 60: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 61: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 62: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 63: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 64: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 65: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 66: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 67: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 68: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 69: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 70: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 71: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 72: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 73: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 74: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 75: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 76: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 77: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 78: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 79: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 80: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 81: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 82: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 83: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 84: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 85: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 86: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 87: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 88: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 89: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 90: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 91: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 92: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 93: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 94: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 95: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 96: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 97: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 98: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 99: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 100: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 101: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 102: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 103: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 104: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 105: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 106: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 107: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 108: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 109: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 110: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 111: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 112: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 113: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 114: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 115: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 116: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 117: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 118: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 119: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 120: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 121: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 122: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 123: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 124: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 125: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 126: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 127: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 128: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 129: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 130: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 131: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 132: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 133: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 134: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 135: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 136: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 137: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 138: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 139: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 140: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 141: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 142: Predicted = 1, Actual = 0, ❌\n",
            "🖼 Sample 143: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 144: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 145: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 146: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 147: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 148: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 149: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 150: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 151: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 152: Predicted = 0, Actual = 1, ❌\n",
            "🖼 Sample 153: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 154: Predicted = 0, Actual = 0, ✅\n",
            "🖼 Sample 155: Predicted = 1, Actual = 1, ✅\n",
            "🖼 Sample 156: Predicted = 1, Actual = 1, ✅\n",
            "\n",
            "🎯 Model Accuracy: 82.69% on BreastMNIST test set\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the data flag\n",
        "data_flag = 'breastmnist'  # Dataset used\n",
        "\n",
        "# Load info for the dataset\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Define the MedMNIST dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Preprocessing transformation for the dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),  # Convert to RGB if necessary\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Single sample inference\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load the trained weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function for inference\n",
        "def inference(model, dataloader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs = inputs.cuda()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # If the task is binary classification or multi-class classification\n",
        "            _, predicted = torch.max(outputs, 1)  # Get the index of the class with the highest score\n",
        "\n",
        "            # Convert prediction and target to CPU for visualization or analysis\n",
        "            predicted_class = predicted.item()\n",
        "            true_class = targets.item()\n",
        "\n",
        "            print(f\"True Class: {true_class}, Predicted Class: {predicted_class}\")\n",
        "            return predicted_class, true_class  # You can return the prediction for further analysis\n",
        "\n",
        "# Perform inference on a single batch from the test dataset\n",
        "inference(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBJXbesl6G1e",
        "outputId": "69d0c111-d1b2-4ecb-e402-80c96b1e7572"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "True Class: 0, Predicted Class: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "from torch.utils.data import DataLoader\n",
        "from MedViT import MedViT_small as tiny\n",
        "\n",
        "# Define the data flag\n",
        "data_flag = 'breastmnist'  # Dataset used\n",
        "\n",
        "# Load info for the dataset\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "# Define the MedMNIST dataset class\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "# Preprocessing transformation for the dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.Lambda(lambda image: image.convert('RGB')),  # Convert to RGB if necessary\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])\n",
        "])\n",
        "\n",
        "# Load the BreastMNIST test dataset\n",
        "test_dataset = DataClass(split='test', transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)  # Process multiple samples at once\n",
        "\n",
        "# Load the trained model\n",
        "model = tiny()\n",
        "model.proj_head[0] = torch.nn.Linear(in_features=1024, out_features=2, bias=True)  # Adjust output layer\n",
        "model = model.cuda()\n",
        "\n",
        "# Load the trained weights\n",
        "model.load_state_dict(torch.load(\"model.pth\"))\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Function for inference on the entire dataset\n",
        "def inference_on_all_samples(model, dataloader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs = inputs.cuda()\n",
        "            targets = targets.cuda()\n",
        "\n",
        "            # Forward pass through the model\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # For multi-class classification, get the class with the highest score\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            # Store predictions and true labels\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_true.extend(targets.cpu().numpy())\n",
        "\n",
        "    return all_true, all_preds\n",
        "\n",
        "# Perform inference on the entire test dataset\n",
        "true_labels, predicted_labels = inference_on_all_samples(model, test_loader)\n",
        "\n",
        "# You can then compare the true and predicted labels\n",
        "correct = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred])\n",
        "accuracy = correct / len(true_labels)\n",
        "\n",
        "print(f\"Accuracy on the entire test set: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL0P-D1e6UsG",
        "outputId": "a09428e0-e2e5-44db-d8df-82d36e8503c9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "Accuracy on the entire test set: 82.69%\n"
          ]
        }
      ]
    }
  ]
}