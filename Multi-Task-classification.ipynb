{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten, Input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory\n",
    "base_dir = 'medical-images/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: ['bloodmnist', 'octmnist', 'pathmnist']\n"
     ]
    }
   ],
   "source": [
    "# Extract dataset names (e.g., PathMNIST, BreastMNIST, BloodMNIST) and class count\n",
    "datasets = os.listdir(base_dir)\n",
    "datasets = sorted(datasets)  # Ensure consistent ordering\n",
    "print(f\"Datasets: {datasets}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bloodmnist has classes: ['0', '1', '2', '3', '4', '5', '6', '7']\n",
      "octmnist has classes: ['0', '1', '2', '3']\n",
      "pathmnist has classes: ['0', '1', '2', '3', '4', '5', '6', '7', '8', 'PathMNIST of size 28.docx', 'pathmnist.zip']\n"
     ]
    }
   ],
   "source": [
    "# Parse classes under each dataset\n",
    "dataset_classes = {dataset: sorted(os.listdir(os.path.join(base_dir, dataset))) for dataset in datasets}\n",
    "for dataset, classes in dataset_classes.items():\n",
    "    print(f\"{dataset} has classes: {classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset creation\n",
    "img_size = 180\n",
    "batch_size = 32\n",
    "\n",
    "# Custom function to parse dataset and class labels from file paths\n",
    "def extract_labels(file_path):\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    dataset_name = parts[-3]  # Extract dataset name (e.g., PathMNIST)\n",
    "    class_name = parts[-2]   # Extract class name (e.g., class0)\n",
    "    dataset_index = datasets.index(dataset_name.numpy().decode())  # Convert dataset name to index\n",
    "    class_index = int(class_name.numpy().decode().replace('class', ''))  # Extract class index\n",
    "    return dataset_index, class_index\n",
    "\n",
    "def preprocess_data(file_path, label):\n",
    "    dataset_label, class_label = tf.py_function(func=extract_labels, inp=[file_path], Tout=[tf.int32, tf.int32])\n",
    "    image = tf.image.decode_image(tf.io.read_file(file_path), channels=3)\n",
    "    image = tf.image.resize(image, (img_size, img_size)) / 255.0\n",
    "    return image, (dataset_label, class_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81145 files belonging to 3 classes.\n",
      "Using 64916 files for training.\n",
      "Found 81145 files belonging to 3 classes.\n",
      "Using 16229 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\miniconda3\\envs\\dl\\Lib\\site-packages\\keras\\src\\layers\\preprocessing\\tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">90</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30976</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30976</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,965,056</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dataset_output      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,419</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m,  │        \u001b[38;5;34m448\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m90\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m16\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m90\u001b[0m, \u001b[38;5;34m90\u001b[0m,    │      \u001b[38;5;34m4,640\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m45\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m45\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30976\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30976\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m3,965,056\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dataset_output      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m387\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)        │      \u001b[38;5;34m1,419\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,990,446</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,990,446\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,990,446</span> (15.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,990,446\u001b[0m (15.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load datasets with labels\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    label_mode=\"int\",  # Include labels as integers\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    label_mode=\"int\",  # Include labels as integers\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "# Preprocess data function\n",
    "def preprocess_data(image, label):\n",
    "    image = tf.image.resize(image, (img_size, img_size)) / 255.0  # Normalize images\n",
    "    return image, label\n",
    "\n",
    "# Map preprocessing function\n",
    "train_ds = train_ds.map(preprocess_data)\n",
    "val_ds = val_ds.map(preprocess_data)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(img_size, img_size, 3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Multi-Task Model\n",
    "inputs = tf.keras.Input(shape=(img_size, img_size, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = layers.Conv2D(16, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "shared_features = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# Output 1: Dataset classification\n",
    "dataset_output = layers.Dense(len(datasets), activation='softmax', name='dataset_output')(shared_features)\n",
    "\n",
    "# Output 2: Class classification\n",
    "max_classes = max(len(classes) for classes in dataset_classes.values())  # Maximum number of classes\n",
    "class_output = layers.Dense(max_classes, activation='softmax', name='class_output')(shared_features)\n",
    "\n",
    "# Compile model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=[dataset_output, class_output])\n",
    "model.compile(optimizer='adam',\n",
    "              loss={\n",
    "                  'dataset_output': 'sparse_categorical_crossentropy',\n",
    "                  'class_output': 'sparse_categorical_crossentropy'\n",
    "              },\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping function to structure labels for multi-task learning\n",
    "def prepare_labels(image, label):\n",
    "    # Assuming `label` contains the class index\n",
    "    # You need a way to map each class index to the dataset index\n",
    "    dataset_label = tf.constant(0, dtype=tf.int32)  # Replace with your dataset mapping logic\n",
    "    return image, (dataset_label, label)\n",
    "\n",
    "# Apply the mapping function to structure the dataset\n",
    "train_ds = train_ds.map(prepare_labels)\n",
    "val_ds = val_ds.map(prepare_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label preprocessing\n",
    "def prepare_labels(image, label):\n",
    "    # Map labels appropriately\n",
    "    dataset_label = tf.constant(0, dtype=tf.int32)  # Adjust to your dataset-label logic\n",
    "    return image, (dataset_label, label)\n",
    "\n",
    "# Apply the label preparation to the datasets\n",
    "train_ds = train_ds.map(prepare_labels)\n",
    "val_ds = val_ds.map(prepare_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (32, 180, 180, 3)\n",
      "Dataset labels: 0\n",
      "Class labels: (<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
      "array([0, 0, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 0, 2, 2, 1, 2, 2, 0, 1, 2,\n",
      "       1, 2, 1, 2, 2, 2, 2, 2, 1, 0], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for images, (dataset_labels, class_labels) in train_ds.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Dataset labels: {dataset_labels}\")\n",
    "    print(f\"Class labels: {class_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prediction shape: (32, 3)\n",
      "Class prediction shape: (32, 11)\n"
     ]
    }
   ],
   "source": [
    "sample_images, (sample_dataset_labels, sample_class_labels) = next(iter(train_ds))\n",
    "sample_predictions = model(sample_images)\n",
    "print(f\"Dataset prediction shape: {sample_predictions[0].shape}\")\n",
    "print(f\"Class prediction shape: {sample_predictions[1].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 81145 files belonging to 3 classes.\n",
      "Using 64916 files for training.\n",
      "Found 81145 files belonging to 3 classes.\n",
      "Using 16229 files for validation.\n",
      "Epoch 1/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 209ms/step - class_output_accuracy: 0.9785 - class_output_loss: 1.2822 - dataset_output_accuracy: 0.9981 - dataset_output_loss: 0.0324 - loss: 1.3145 - val_class_output_accuracy: 0.9904 - val_class_output_loss: 0.2701 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 4.3897e-07 - val_loss: 0.2583\n",
      "Epoch 2/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 218ms/step - class_output_accuracy: 0.9899 - class_output_loss: 0.1404 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 6.0846e-05 - loss: 0.1405 - val_class_output_accuracy: 0.9988 - val_class_output_loss: 0.0091 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0091\n",
      "Epoch 3/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 172ms/step - class_output_accuracy: 0.9978 - class_output_loss: 0.0140 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 3.2730e-08 - loss: 0.0140 - val_class_output_accuracy: 0.9983 - val_class_output_loss: 0.0233 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 1.4666e-11 - val_loss: 0.0234\n",
      "Epoch 4/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 198ms/step - class_output_accuracy: 0.9976 - class_output_loss: 0.0159 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 4.3666e-05 - loss: 0.0160 - val_class_output_accuracy: 0.9992 - val_class_output_loss: 0.0044 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 2.7133e-10 - val_loss: 0.0044\n",
      "Epoch 5/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 196ms/step - class_output_accuracy: 0.9977 - class_output_loss: 0.0165 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 1.0071e-05 - loss: 0.0165 - val_class_output_accuracy: 0.9992 - val_class_output_loss: 0.0084 - val_dataset_output_accuracy: 0.9998 - val_dataset_output_loss: 3.9114e-04 - val_loss: 0.0088\n",
      "Epoch 6/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 174ms/step - class_output_accuracy: 0.9982 - class_output_loss: 0.0146 - dataset_output_accuracy: 0.9999 - dataset_output_loss: 5.2312e-04 - loss: 0.0151 - val_class_output_accuracy: 0.9993 - val_class_output_loss: 0.0074 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0074\n",
      "Epoch 7/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 157ms/step - class_output_accuracy: 0.9982 - class_output_loss: 0.0170 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 6.4145e-07 - loss: 0.0170 - val_class_output_accuracy: 0.9974 - val_class_output_loss: 0.1733 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.1736\n",
      "Epoch 8/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 157ms/step - class_output_accuracy: 0.9982 - class_output_loss: 0.0542 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 2.2812e-04 - loss: 0.0544 - val_class_output_accuracy: 0.9996 - val_class_output_loss: 0.0026 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0026\n",
      "Epoch 9/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 157ms/step - class_output_accuracy: 0.9989 - class_output_loss: 0.0288 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 1.3756e-04 - loss: 0.0289 - val_class_output_accuracy: 0.9993 - val_class_output_loss: 0.0044 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0044\n",
      "Epoch 10/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 156ms/step - class_output_accuracy: 0.9993 - class_output_loss: 0.0090 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 9.2106e-05 - loss: 0.0091 - val_class_output_accuracy: 0.9996 - val_class_output_loss: 0.0023 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0023\n",
      "Epoch 11/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 151ms/step - class_output_accuracy: 0.9992 - class_output_loss: 0.0122 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 1.2719e-04 - loss: 0.0123 - val_class_output_accuracy: 0.9986 - val_class_output_loss: 0.0526 - val_dataset_output_accuracy: 0.9999 - val_dataset_output_loss: 2.7468e-04 - val_loss: 0.0530\n",
      "Epoch 12/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 153ms/step - class_output_accuracy: 0.9989 - class_output_loss: 0.0216 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 3.9069e-04 - loss: 0.0220 - val_class_output_accuracy: 0.9991 - val_class_output_loss: 0.0071 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 3.3724e-05 - val_loss: 0.0071\n",
      "Epoch 13/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 211ms/step - class_output_accuracy: 0.9990 - class_output_loss: 0.0064 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 8.6018e-07 - loss: 0.0064 - val_class_output_accuracy: 0.9998 - val_class_output_loss: 0.0026 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 1.3324e-05 - val_loss: 0.0026\n",
      "Epoch 14/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 152ms/step - class_output_accuracy: 0.9988 - class_output_loss: 0.0457 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 2.0757e-05 - loss: 0.0457 - val_class_output_accuracy: 0.9993 - val_class_output_loss: 0.0101 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 0.0000e+00 - val_loss: 0.0101\n",
      "Epoch 15/15\n",
      "\u001b[1m2029/2029\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 172ms/step - class_output_accuracy: 0.9986 - class_output_loss: 0.0283 - dataset_output_accuracy: 1.0000 - dataset_output_loss: 5.4433e-06 - loss: 0.0283 - val_class_output_accuracy: 0.9995 - val_class_output_loss: 0.0031 - val_dataset_output_accuracy: 1.0000 - val_dataset_output_loss: 7.2617e-07 - val_loss: 0.0031\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "img_size = 128\n",
    "batch_size = 32\n",
    "datasets = ['bloodmnist', 'octmnist', 'pathmnist']  # Adjust this based on your datasets\n",
    "dataset_classes = {'bloodmnist': ['0', '1', '2', '3', '4', '5', '6', '7'],\n",
    "                   'octmnist': ['0', '1', '2', '3'],\n",
    "                   'pathmnist': ['0', '1', '2', '3', '4', '5', '6', '7', '8']}\n",
    "base_dir = 'medical-images'  # Replace with your dataset path\n",
    "\n",
    "# Dataset label mapping\n",
    "dataset_labels_map = {dataset: i for i, dataset in enumerate(datasets)}\n",
    "\n",
    "# Load datasets\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    label_mode=\"int\",  # Include labels as integers\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    label_mode=\"int\",  # Include labels as integers\n",
    "    seed=123,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_size, img_size)\n",
    ")\n",
    "\n",
    "# Define label preprocessing\n",
    "def prepare_labels(image, label):\n",
    "    # Determine dataset label based on the folder structure in the dataset directory\n",
    "    dataset_label = label // 100  # Assuming dataset labels are in batches of 100 images per dataset\n",
    "    class_label = label % 100  # Get the class within the dataset\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    dataset_label_one_hot = tf.one_hot(dataset_label, len(datasets))\n",
    "    return image, {'dataset_output': dataset_label_one_hot, 'class_output': class_label}\n",
    "\n",
    "# Map dataset label preparation to train and validation datasets\n",
    "train_ds = train_ds.map(prepare_labels)\n",
    "val_ds = val_ds.map(prepare_labels)\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = Sequential([\n",
    "    layers.RandomFlip(\"horizontal\", input_shape=(img_size, img_size, 3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "# Multi-task learning model\n",
    "inputs = Input(shape=(img_size, img_size, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = Conv2D(16, 3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(32, 3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "shared_features = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Output 1: Dataset classification\n",
    "dataset_output = Dense(len(datasets), activation='softmax', name='dataset_output')(shared_features)\n",
    "\n",
    "# Output 2: Class classification\n",
    "max_classes = max(len(classes) for classes in dataset_classes.values())  # Maximum number of classes\n",
    "class_output = Dense(max_classes, activation='softmax', name='class_output')(shared_features)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs=inputs, outputs=[dataset_output, class_output])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'dataset_output': 'categorical_crossentropy',  # Changed to categorical_crossentropy\n",
    "        'class_output': 'sparse_categorical_crossentropy',\n",
    "    },\n",
    "    metrics={\n",
    "        'dataset_output': 'accuracy',  # Added metrics for each output\n",
    "        'class_output': 'accuracy'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15\n",
    ")\n",
    "\n",
    "# Classify an image\n",
    "def classify_image(image_path):\n",
    "    input_image = tf.keras.utils.load_img(image_path, target_size=(img_size, img_size))\n",
    "    input_image_array = tf.keras.utils.img_to_array(input_image)\n",
    "    input_image_exp_dim = tf.expand_dims(input_image_array / 255.0, 0)\n",
    "\n",
    "    dataset_pred, class_pred = model.predict(input_image_exp_dim)\n",
    "    dataset_index = np.argmax(dataset_pred[0])\n",
    "    class_index = np.argmax(class_pred[0])\n",
    "\n",
    "    return f\"The image belongs to {datasets[dataset_index]} and class {class_index}.\"\n",
    "\n",
    "# Example usage\n",
    "# result = classify_image('path/to/test/image.jpg')\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_1484\\3181913275.py:2: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  result = classify_image('medical-images\\image_1_class_2.png')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step\n",
      "The image belongs to bloodmnist and class 2.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "result = classify_image('medical-images\\image_1_class_2.png')\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
