{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c505004",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T12:35:14.504987Z",
     "iopub.status.busy": "2025-02-19T12:35:14.504784Z",
     "iopub.status.idle": "2025-02-19T12:35:21.126092Z",
     "shell.execute_reply": "2025-02-19T12:35:21.124965Z"
    },
    "papermill": {
     "duration": 6.625887,
     "end_time": "2025-02-19T12:35:21.127832",
     "exception": false,
     "start_time": "2025-02-19T12:35:14.501945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q medmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9def62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T12:35:21.134308Z",
     "iopub.status.busy": "2025-02-19T12:35:21.134008Z",
     "iopub.status.idle": "2025-02-19T21:38:20.252368Z",
     "shell.execute_reply": "2025-02-19T21:38:20.251075Z"
    },
    "papermill": {
     "duration": 32579.123668,
     "end_time": "2025-02-19T21:38:20.254197",
     "exception": false,
     "start_time": "2025-02-19T12:35:21.130529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pathmnist...\n",
      "Loading dermamnist...\n",
      "Loading octmnist...\n",
      "Loading pneumoniamnist...\n",
      "Loading retinamnist...\n",
      "Loading breastmnist...\n",
      "Loading bloodmnist...\n",
      "Loading tissuemnist...\n",
      "Loading organamnist...\n",
      "Loading organcmnist...\n",
      "Loading organsmnist...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a63651874d84ef0a783d7f41f072039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-596e5a40956e>:250: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler(enabled=config['use_amp']) # Use standard GradScaler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:17<00:00,  1.14s/it, loss=1.32]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3166 | Train F1 (Harmonic): 0.2892\n",
      "Val Loss:   1.2339 | Val Metric (recall):   0.5238\n",
      "  - pathmnist: F1 = 0.6693, Recall = 0.6724\n",
      "  - dermamnist: F1 = 0.1390, Recall = 0.1565\n",
      "  - octmnist: F1 = 0.6249, Recall = 0.6135\n",
      "  - pneumoniamnist: F1 = 0.8515, Recall = 0.8958\n",
      "  - retinamnist: F1 = 0.2266, Recall = 0.2504\n",
      "  - breastmnist: F1 = 0.4708, Recall = 0.5238\n",
      "  - bloodmnist: F1 = 0.6050, Recall = 0.6398\n",
      "  - tissuemnist: F1 = 0.3839, Recall = 0.3816\n",
      "  - organamnist: F1 = 0.7826, Recall = 0.8020\n",
      "  - organcmnist: F1 = 0.6326, Recall = 0.6790\n",
      "  - organsmnist: F1 = 0.4250, Recall = 0.4812\n",
      "Saved best model.\n",
      "\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:25<00:00,  1.15s/it, loss=0.886]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8856 | Train F1 (Harmonic): 0.3983\n",
      "Val Loss:   0.9663 | Val Metric (recall):   0.5000\n",
      "  - pathmnist: F1 = 0.7587, Recall = 0.7516\n",
      "  - dermamnist: F1 = 0.1813, Recall = 0.1906\n",
      "  - octmnist: F1 = 0.7336, Recall = 0.7209\n",
      "  - pneumoniamnist: F1 = 0.9190, Recall = 0.9394\n",
      "  - retinamnist: F1 = 0.1497, Recall = 0.2106\n",
      "  - breastmnist: F1 = 0.4222, Recall = 0.5000\n",
      "  - bloodmnist: F1 = 0.7610, Recall = 0.7534\n",
      "  - tissuemnist: F1 = 0.4654, Recall = 0.4481\n",
      "  - organamnist: F1 = 0.9320, Recall = 0.9253\n",
      "  - organcmnist: F1 = 0.8289, Recall = 0.8490\n",
      "  - organsmnist: F1 = 0.6194, Recall = 0.6602\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:22<00:00,  1.14s/it, loss=0.75]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7502 | Train F1 (Harmonic): 0.4664\n",
      "Val Loss:   0.8516 | Val Metric (recall):   0.5238\n",
      "  - pathmnist: F1 = 0.8369, Recall = 0.8403\n",
      "  - dermamnist: F1 = 0.2782, Recall = 0.2695\n",
      "  - octmnist: F1 = 0.7655, Recall = 0.7521\n",
      "  - pneumoniamnist: F1 = 0.8035, Recall = 0.8780\n",
      "  - retinamnist: F1 = 0.2305, Recall = 0.2670\n",
      "  - breastmnist: F1 = 0.4708, Recall = 0.5238\n",
      "  - bloodmnist: F1 = 0.7644, Recall = 0.7618\n",
      "  - tissuemnist: F1 = 0.5098, Recall = 0.5072\n",
      "  - organamnist: F1 = 0.9819, Recall = 0.9814\n",
      "  - organcmnist: F1 = 0.9143, Recall = 0.9173\n",
      "  - organsmnist: F1 = 0.7233, Recall = 0.7386\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:23<00:00,  1.15s/it, loss=0.728]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7275 | Train F1 (Harmonic): 0.5118\n",
      "Val Loss:   0.8108 | Val Metric (recall):   0.6341\n",
      "  - pathmnist: F1 = 0.8299, Recall = 0.8323\n",
      "  - dermamnist: F1 = 0.2374, Recall = 0.2400\n",
      "  - octmnist: F1 = 0.7780, Recall = 0.7662\n",
      "  - pneumoniamnist: F1 = 0.9272, Recall = 0.9108\n",
      "  - retinamnist: F1 = 0.1903, Recall = 0.2264\n",
      "  - breastmnist: F1 = 0.6518, Recall = 0.6341\n",
      "  - bloodmnist: F1 = 0.8549, Recall = 0.8517\n",
      "  - tissuemnist: F1 = 0.5258, Recall = 0.5175\n",
      "  - organamnist: F1 = 0.9772, Recall = 0.9772\n",
      "  - organcmnist: F1 = 0.9510, Recall = 0.9523\n",
      "  - organsmnist: F1 = 0.7692, Recall = 0.7747\n",
      "Saved best model.\n",
      "\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:26<00:00,  1.15s/it, loss=0.688]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6878 | Train F1 (Harmonic): 0.5310\n",
      "Val Loss:   0.8034 | Val Metric (recall):   0.5238\n",
      "  - pathmnist: F1 = 0.8300, Recall = 0.8301\n",
      "  - dermamnist: F1 = 0.2922, Recall = 0.2783\n",
      "  - octmnist: F1 = 0.7789, Recall = 0.7553\n",
      "  - pneumoniamnist: F1 = 0.8988, Recall = 0.9362\n",
      "  - retinamnist: F1 = 0.1233, Recall = 0.1963\n",
      "  - breastmnist: F1 = 0.4708, Recall = 0.5238\n",
      "  - bloodmnist: F1 = 0.8113, Recall = 0.8007\n",
      "  - tissuemnist: F1 = 0.5292, Recall = 0.5258\n",
      "  - organamnist: F1 = 0.9856, Recall = 0.9840\n",
      "  - organcmnist: F1 = 0.9712, Recall = 0.9742\n",
      "  - organsmnist: F1 = 0.7944, Recall = 0.8053\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:18<00:00,  1.14s/it, loss=0.67]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6703 | Train F1 (Harmonic): 0.5558\n",
      "Val Loss:   0.9778 | Val Metric (recall):   0.6429\n",
      "  - pathmnist: F1 = 0.8294, Recall = 0.8340\n",
      "  - dermamnist: F1 = 0.3122, Recall = 0.2725\n",
      "  - octmnist: F1 = 0.6647, Recall = 0.6389\n",
      "  - pneumoniamnist: F1 = 0.9395, Recall = 0.9534\n",
      "  - retinamnist: F1 = 0.1241, Recall = 0.2000\n",
      "  - breastmnist: F1 = 0.6641, Recall = 0.6429\n",
      "  - bloodmnist: F1 = 0.8053, Recall = 0.8145\n",
      "  - tissuemnist: F1 = 0.4603, Recall = 0.4557\n",
      "  - organamnist: F1 = 0.9698, Recall = 0.9736\n",
      "  - organcmnist: F1 = 0.9317, Recall = 0.9372\n",
      "  - organsmnist: F1 = 0.7804, Recall = 0.8104\n",
      "Saved best model.\n",
      "\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:20<00:00,  1.14s/it, loss=0.664]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6644 | Train F1 (Harmonic): 0.5510\n",
      "Val Loss:   0.7732 | Val Metric (recall):   0.7569\n",
      "  - pathmnist: F1 = 0.8453, Recall = 0.8453\n",
      "  - dermamnist: F1 = 0.2878, Recall = 0.2896\n",
      "  - octmnist: F1 = 0.7631, Recall = 0.7336\n",
      "  - pneumoniamnist: F1 = 0.9389, Recall = 0.9485\n",
      "  - retinamnist: F1 = 0.2425, Recall = 0.2673\n",
      "  - breastmnist: F1 = 0.7647, Recall = 0.7569\n",
      "  - bloodmnist: F1 = 0.8491, Recall = 0.8436\n",
      "  - tissuemnist: F1 = 0.5306, Recall = 0.5240\n",
      "  - organamnist: F1 = 0.9846, Recall = 0.9851\n",
      "  - organcmnist: F1 = 0.9670, Recall = 0.9661\n",
      "  - organsmnist: F1 = 0.8278, Recall = 0.8228\n",
      "Saved best model.\n",
      "\n",
      "Epoch 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:51<00:00,  1.18s/it, loss=0.654]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6543 | Train F1 (Harmonic): 0.5461\n",
      "Val Loss:   0.7842 | Val Metric (recall):   0.6817\n",
      "  - pathmnist: F1 = 0.8500, Recall = 0.8461\n",
      "  - dermamnist: F1 = 0.2886, Recall = 0.2794\n",
      "  - octmnist: F1 = 0.7689, Recall = 0.7458\n",
      "  - pneumoniamnist: F1 = 0.9073, Recall = 0.9413\n",
      "  - retinamnist: F1 = 0.2093, Recall = 0.2422\n",
      "  - breastmnist: F1 = 0.7111, Recall = 0.6817\n",
      "  - bloodmnist: F1 = 0.8597, Recall = 0.8718\n",
      "  - tissuemnist: F1 = 0.5171, Recall = 0.5313\n",
      "  - organamnist: F1 = 0.9777, Recall = 0.9762\n",
      "  - organcmnist: F1 = 0.9550, Recall = 0.9562\n",
      "  - organsmnist: F1 = 0.7929, Recall = 0.8206\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:48<00:00,  1.17s/it, loss=0.639]\n",
      "Validating: 100%|██████████| 116/116 [01:20<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6395 | Train F1 (Harmonic): 0.5574\n",
      "Val Loss:   0.8288 | Val Metric (recall):   0.7419\n",
      "  - pathmnist: F1 = 0.8709, Recall = 0.8681\n",
      "  - dermamnist: F1 = 0.2553, Recall = 0.2346\n",
      "  - octmnist: F1 = 0.7307, Recall = 0.7176\n",
      "  - pneumoniamnist: F1 = 0.9321, Recall = 0.9447\n",
      "  - retinamnist: F1 = 0.2387, Recall = 0.2580\n",
      "  - breastmnist: F1 = 0.7565, Recall = 0.7419\n",
      "  - bloodmnist: F1 = 0.8800, Recall = 0.8686\n",
      "  - tissuemnist: F1 = 0.5165, Recall = 0.5077\n",
      "  - organamnist: F1 = 0.9905, Recall = 0.9899\n",
      "  - organcmnist: F1 = 0.9670, Recall = 0.9689\n",
      "  - organsmnist: F1 = 0.7980, Recall = 0.8192\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:35<00:00,  1.16s/it, loss=0.627]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6269 | Train F1 (Harmonic): 0.5682\n",
      "Val Loss:   0.7869 | Val Metric (recall):   0.6579\n",
      "  - pathmnist: F1 = 0.8235, Recall = 0.8233\n",
      "  - dermamnist: F1 = 0.2970, Recall = 0.3011\n",
      "  - octmnist: F1 = 0.8158, Recall = 0.7933\n",
      "  - pneumoniamnist: F1 = 0.9042, Recall = 0.9460\n",
      "  - retinamnist: F1 = 0.3056, Recall = 0.3521\n",
      "  - breastmnist: F1 = 0.6823, Recall = 0.6579\n",
      "  - bloodmnist: F1 = 0.8695, Recall = 0.8838\n",
      "  - tissuemnist: F1 = 0.5110, Recall = 0.5024\n",
      "  - organamnist: F1 = 0.9902, Recall = 0.9900\n",
      "  - organcmnist: F1 = 0.9696, Recall = 0.9682\n",
      "  - organsmnist: F1 = 0.8214, Recall = 0.8266\n",
      "Early stopping counter: 3/7\n",
      "\n",
      "Epoch 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:26<00:00,  1.15s/it, loss=0.592]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5918 | Train F1 (Harmonic): 0.6002\n",
      "Val Loss:   0.7161 | Val Metric (recall):   0.6905\n",
      "  - pathmnist: F1 = 0.8821, Recall = 0.8849\n",
      "  - dermamnist: F1 = 0.3387, Recall = 0.3168\n",
      "  - octmnist: F1 = 0.8317, Recall = 0.8093\n",
      "  - pneumoniamnist: F1 = 0.9250, Recall = 0.9540\n",
      "  - retinamnist: F1 = 0.2252, Recall = 0.3144\n",
      "  - breastmnist: F1 = 0.7247, Recall = 0.6905\n",
      "  - bloodmnist: F1 = 0.8931, Recall = 0.8982\n",
      "  - tissuemnist: F1 = 0.5650, Recall = 0.5495\n",
      "  - organamnist: F1 = 0.9842, Recall = 0.9843\n",
      "  - organcmnist: F1 = 0.9685, Recall = 0.9697\n",
      "  - organsmnist: F1 = 0.8099, Recall = 0.8351\n",
      "Early stopping counter: 4/7\n",
      "\n",
      "Epoch 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:24<00:00,  1.15s/it, loss=0.597]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5972 | Train F1 (Harmonic): 0.6062\n",
      "Val Loss:   0.7086 | Val Metric (recall):   0.7293\n",
      "  - pathmnist: F1 = 0.8510, Recall = 0.8499\n",
      "  - dermamnist: F1 = 0.2997, Recall = 0.2678\n",
      "  - octmnist: F1 = 0.8106, Recall = 0.7849\n",
      "  - pneumoniamnist: F1 = 0.9247, Recall = 0.9516\n",
      "  - retinamnist: F1 = 0.2611, Recall = 0.2831\n",
      "  - breastmnist: F1 = 0.7641, Recall = 0.7293\n",
      "  - bloodmnist: F1 = 0.8489, Recall = 0.8286\n",
      "  - tissuemnist: F1 = 0.5824, Recall = 0.5870\n",
      "  - organamnist: F1 = 0.9854, Recall = 0.9862\n",
      "  - organcmnist: F1 = 0.9762, Recall = 0.9746\n",
      "  - organsmnist: F1 = 0.7911, Recall = 0.8168\n",
      "Early stopping counter: 5/7\n",
      "\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:22<00:00,  1.14s/it, loss=0.577]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5769 | Train F1 (Harmonic): 0.6027\n",
      "Val Loss:   0.7019 | Val Metric (recall):   0.7444\n",
      "  - pathmnist: F1 = 0.8824, Recall = 0.8845\n",
      "  - dermamnist: F1 = 0.3665, Recall = 0.3236\n",
      "  - octmnist: F1 = 0.8248, Recall = 0.8434\n",
      "  - pneumoniamnist: F1 = 0.9625, Recall = 0.9614\n",
      "  - retinamnist: F1 = 0.3398, Recall = 0.3481\n",
      "  - breastmnist: F1 = 0.7743, Recall = 0.7444\n",
      "  - bloodmnist: F1 = 0.9081, Recall = 0.9052\n",
      "  - tissuemnist: F1 = 0.5275, Recall = 0.5384\n",
      "  - organamnist: F1 = 0.9860, Recall = 0.9867\n",
      "  - organcmnist: F1 = 0.9716, Recall = 0.9735\n",
      "  - organsmnist: F1 = 0.8399, Recall = 0.8477\n",
      "Early stopping counter: 6/7\n",
      "\n",
      "Epoch 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:24<00:00,  1.15s/it, loss=0.562]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5621 | Train F1 (Harmonic): 0.6207\n",
      "Val Loss:   0.6635 | Val Metric (recall):   0.7682\n",
      "  - pathmnist: F1 = 0.8839, Recall = 0.8838\n",
      "  - dermamnist: F1 = 0.3542, Recall = 0.3433\n",
      "  - octmnist: F1 = 0.8443, Recall = 0.8351\n",
      "  - pneumoniamnist: F1 = 0.9515, Recall = 0.9646\n",
      "  - retinamnist: F1 = 0.2771, Recall = 0.2932\n",
      "  - breastmnist: F1 = 0.7974, Recall = 0.7682\n",
      "  - bloodmnist: F1 = 0.9098, Recall = 0.9164\n",
      "  - tissuemnist: F1 = 0.5773, Recall = 0.5763\n",
      "  - organamnist: F1 = 0.9869, Recall = 0.9856\n",
      "  - organcmnist: F1 = 0.9792, Recall = 0.9808\n",
      "  - organsmnist: F1 = 0.8031, Recall = 0.8281\n",
      "Saved best model.\n",
      "\n",
      "Epoch 15/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:22<00:00,  1.14s/it, loss=0.544]\n",
      "Validating: 100%|██████████| 116/116 [01:18<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5443 | Train F1 (Harmonic): 0.6231\n",
      "Val Loss:   0.7663 | Val Metric (recall):   0.8158\n",
      "  - pathmnist: F1 = 0.8828, Recall = 0.8835\n",
      "  - dermamnist: F1 = 0.3283, Recall = 0.2979\n",
      "  - octmnist: F1 = 0.8209, Recall = 0.7876\n",
      "  - pneumoniamnist: F1 = 0.8496, Recall = 0.9113\n",
      "  - retinamnist: F1 = 0.3198, Recall = 0.3230\n",
      "  - breastmnist: F1 = 0.8406, Recall = 0.8158\n",
      "  - bloodmnist: F1 = 0.9125, Recall = 0.9094\n",
      "  - tissuemnist: F1 = 0.5240, Recall = 0.5198\n",
      "  - organamnist: F1 = 0.9889, Recall = 0.9897\n",
      "  - organcmnist: F1 = 0.9698, Recall = 0.9719\n",
      "  - organsmnist: F1 = 0.8409, Recall = 0.8455\n",
      "Saved best model.\n",
      "\n",
      "Epoch 16/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:30<00:00,  1.15s/it, loss=0.504]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5038 | Train F1 (Harmonic): 0.6544\n",
      "Val Loss:   0.6450 | Val Metric (recall):   0.7920\n",
      "  - pathmnist: F1 = 0.9029, Recall = 0.9012\n",
      "  - dermamnist: F1 = 0.3785, Recall = 0.3610\n",
      "  - octmnist: F1 = 0.8591, Recall = 0.8341\n",
      "  - pneumoniamnist: F1 = 0.9612, Recall = 0.9746\n",
      "  - retinamnist: F1 = 0.3169, Recall = 0.3308\n",
      "  - breastmnist: F1 = 0.8194, Recall = 0.7920\n",
      "  - bloodmnist: F1 = 0.9239, Recall = 0.9241\n",
      "  - tissuemnist: F1 = 0.6004, Recall = 0.5923\n",
      "  - organamnist: F1 = 0.9853, Recall = 0.9848\n",
      "  - organcmnist: F1 = 0.9809, Recall = 0.9813\n",
      "  - organsmnist: F1 = 0.8342, Recall = 0.8586\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:27<00:00,  1.15s/it, loss=0.477]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4773 | Train F1 (Harmonic): 0.6709\n",
      "Val Loss:   0.6713 | Val Metric (recall):   0.6579\n",
      "  - pathmnist: F1 = 0.9159, Recall = 0.9168\n",
      "  - dermamnist: F1 = 0.3429, Recall = 0.3321\n",
      "  - octmnist: F1 = 0.8572, Recall = 0.8336\n",
      "  - pneumoniamnist: F1 = 0.9682, Recall = 0.9785\n",
      "  - retinamnist: F1 = 0.3154, Recall = 0.3142\n",
      "  - breastmnist: F1 = 0.6823, Recall = 0.6579\n",
      "  - bloodmnist: F1 = 0.9271, Recall = 0.9240\n",
      "  - tissuemnist: F1 = 0.5667, Recall = 0.5573\n",
      "  - organamnist: F1 = 0.9878, Recall = 0.9873\n",
      "  - organcmnist: F1 = 0.9838, Recall = 0.9836\n",
      "  - organsmnist: F1 = 0.8503, Recall = 0.8587\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 18/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:46<00:00,  1.17s/it, loss=0.465]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4647 | Train F1 (Harmonic): 0.7025\n",
      "Val Loss:   0.6295 | Val Metric (recall):   0.8221\n",
      "  - pathmnist: F1 = 0.9058, Recall = 0.9056\n",
      "  - dermamnist: F1 = 0.4125, Recall = 0.3813\n",
      "  - octmnist: F1 = 0.8569, Recall = 0.8345\n",
      "  - pneumoniamnist: F1 = 0.9632, Recall = 0.9710\n",
      "  - retinamnist: F1 = 0.3106, Recall = 0.3165\n",
      "  - breastmnist: F1 = 0.8319, Recall = 0.8221\n",
      "  - bloodmnist: F1 = 0.9168, Recall = 0.9205\n",
      "  - tissuemnist: F1 = 0.5941, Recall = 0.5926\n",
      "  - organamnist: F1 = 0.9859, Recall = 0.9856\n",
      "  - organcmnist: F1 = 0.9787, Recall = 0.9783\n",
      "  - organsmnist: F1 = 0.8251, Recall = 0.8521\n",
      "Saved best model.\n",
      "\n",
      "Epoch 19/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:27<00:00,  1.15s/it, loss=0.456]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4556 | Train F1 (Harmonic): 0.7043\n",
      "Val Loss:   0.6199 | Val Metric (recall):   0.7682\n",
      "  - pathmnist: F1 = 0.9003, Recall = 0.9017\n",
      "  - dermamnist: F1 = 0.4150, Recall = 0.3942\n",
      "  - octmnist: F1 = 0.8637, Recall = 0.8476\n",
      "  - pneumoniamnist: F1 = 0.9209, Recall = 0.9539\n",
      "  - retinamnist: F1 = 0.3016, Recall = 0.3145\n",
      "  - breastmnist: F1 = 0.7974, Recall = 0.7682\n",
      "  - bloodmnist: F1 = 0.9218, Recall = 0.9215\n",
      "  - tissuemnist: F1 = 0.6010, Recall = 0.5987\n",
      "  - organamnist: F1 = 0.9913, Recall = 0.9914\n",
      "  - organcmnist: F1 = 0.9827, Recall = 0.9853\n",
      "  - organsmnist: F1 = 0.8373, Recall = 0.8469\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:23<00:00,  1.15s/it, loss=0.462]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4619 | Train F1 (Harmonic): 0.7055\n",
      "Val Loss:   0.6324 | Val Metric (recall):   0.7531\n",
      "  - pathmnist: F1 = 0.9116, Recall = 0.9113\n",
      "  - dermamnist: F1 = 0.3424, Recall = 0.3002\n",
      "  - octmnist: F1 = 0.8591, Recall = 0.8314\n",
      "  - pneumoniamnist: F1 = 0.9519, Recall = 0.9695\n",
      "  - retinamnist: F1 = 0.3391, Recall = 0.3471\n",
      "  - breastmnist: F1 = 0.7886, Recall = 0.7531\n",
      "  - bloodmnist: F1 = 0.9265, Recall = 0.9275\n",
      "  - tissuemnist: F1 = 0.5950, Recall = 0.5963\n",
      "  - organamnist: F1 = 0.9900, Recall = 0.9898\n",
      "  - organcmnist: F1 = 0.9820, Recall = 0.9854\n",
      "  - organsmnist: F1 = 0.8439, Recall = 0.8485\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 21/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:42<00:00,  1.17s/it, loss=0.46]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4597 | Train F1 (Harmonic): 0.6917\n",
      "Val Loss:   0.6368 | Val Metric (recall):   0.8008\n",
      "  - pathmnist: F1 = 0.9084, Recall = 0.9062\n",
      "  - dermamnist: F1 = 0.3695, Recall = 0.3370\n",
      "  - octmnist: F1 = 0.8619, Recall = 0.8602\n",
      "  - pneumoniamnist: F1 = 0.9585, Recall = 0.9685\n",
      "  - retinamnist: F1 = 0.3386, Recall = 0.3550\n",
      "  - breastmnist: F1 = 0.8342, Recall = 0.8008\n",
      "  - bloodmnist: F1 = 0.9224, Recall = 0.9349\n",
      "  - tissuemnist: F1 = 0.5918, Recall = 0.5827\n",
      "  - organamnist: F1 = 0.9903, Recall = 0.9897\n",
      "  - organcmnist: F1 = 0.9843, Recall = 0.9866\n",
      "  - organsmnist: F1 = 0.8443, Recall = 0.8457\n",
      "Early stopping counter: 3/7\n",
      "\n",
      "Epoch 22/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:35<00:00,  1.16s/it, loss=0.428]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4278 | Train F1 (Harmonic): 0.7194\n",
      "Val Loss:   0.6152 | Val Metric (recall):   0.8095\n",
      "  - pathmnist: F1 = 0.9280, Recall = 0.9272\n",
      "  - dermamnist: F1 = 0.4147, Recall = 0.3845\n",
      "  - octmnist: F1 = 0.8717, Recall = 0.8510\n",
      "  - pneumoniamnist: F1 = 0.9728, Recall = 0.9762\n",
      "  - retinamnist: F1 = 0.3898, Recall = 0.4097\n",
      "  - breastmnist: F1 = 0.8496, Recall = 0.8095\n",
      "  - bloodmnist: F1 = 0.9367, Recall = 0.9406\n",
      "  - tissuemnist: F1 = 0.6136, Recall = 0.6086\n",
      "  - organamnist: F1 = 0.9907, Recall = 0.9905\n",
      "  - organcmnist: F1 = 0.9898, Recall = 0.9906\n",
      "  - organsmnist: F1 = 0.8464, Recall = 0.8521\n",
      "Early stopping counter: 4/7\n",
      "\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:35<00:00,  1.16s/it, loss=0.39]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3898 | Train F1 (Harmonic): 0.7492\n",
      "Val Loss:   0.5888 | Val Metric (recall):   0.8246\n",
      "  - pathmnist: F1 = 0.9295, Recall = 0.9296\n",
      "  - dermamnist: F1 = 0.4298, Recall = 0.4030\n",
      "  - octmnist: F1 = 0.8837, Recall = 0.8658\n",
      "  - pneumoniamnist: F1 = 0.9540, Recall = 0.9683\n",
      "  - retinamnist: F1 = 0.3843, Recall = 0.3907\n",
      "  - breastmnist: F1 = 0.8556, Recall = 0.8246\n",
      "  - bloodmnist: F1 = 0.9394, Recall = 0.9440\n",
      "  - tissuemnist: F1 = 0.6263, Recall = 0.6236\n",
      "  - organamnist: F1 = 0.9916, Recall = 0.9909\n",
      "  - organcmnist: F1 = 0.9881, Recall = 0.9889\n",
      "  - organsmnist: F1 = 0.8491, Recall = 0.8605\n",
      "Saved best model.\n",
      "\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:39<00:00,  1.16s/it, loss=0.374]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3738 | Train F1 (Harmonic): 0.7575\n",
      "Val Loss:   0.6311 | Val Metric (recall):   0.8070\n",
      "  - pathmnist: F1 = 0.9285, Recall = 0.9283\n",
      "  - dermamnist: F1 = 0.4015, Recall = 0.3625\n",
      "  - octmnist: F1 = 0.8823, Recall = 0.8696\n",
      "  - pneumoniamnist: F1 = 0.9752, Recall = 0.9775\n",
      "  - retinamnist: F1 = 0.3459, Recall = 0.3726\n",
      "  - breastmnist: F1 = 0.8260, Recall = 0.8070\n",
      "  - bloodmnist: F1 = 0.9385, Recall = 0.9349\n",
      "  - tissuemnist: F1 = 0.6091, Recall = 0.5979\n",
      "  - organamnist: F1 = 0.9923, Recall = 0.9919\n",
      "  - organcmnist: F1 = 0.9857, Recall = 0.9875\n",
      "  - organsmnist: F1 = 0.8485, Recall = 0.8532\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 25/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [16:34<00:00,  1.16s/it, loss=0.355]\n",
      "Validating: 100%|██████████| 116/116 [01:19<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3547 | Train F1 (Harmonic): 0.7635\n",
      "Val Loss:   0.6053 | Val Metric (recall):   0.8246\n",
      "  - pathmnist: F1 = 0.9329, Recall = 0.9324\n",
      "  - dermamnist: F1 = 0.4184, Recall = 0.3881\n",
      "  - octmnist: F1 = 0.8863, Recall = 0.8731\n",
      "  - pneumoniamnist: F1 = 0.9656, Recall = 0.9723\n",
      "  - retinamnist: F1 = 0.3457, Recall = 0.3697\n",
      "  - breastmnist: F1 = 0.8556, Recall = 0.8246\n",
      "  - bloodmnist: F1 = 0.9394, Recall = 0.9398\n",
      "  - tissuemnist: F1 = 0.6217, Recall = 0.6157\n",
      "  - organamnist: F1 = 0.9933, Recall = 0.9931\n",
      "  - organcmnist: F1 = 0.9893, Recall = 0.9897\n",
      "  - organsmnist: F1 = 0.8534, Recall = 0.8538\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [17:15<00:00,  1.21s/it, loss=0.347]\n",
      "Validating: 100%|██████████| 116/116 [01:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3472 | Train F1 (Harmonic): 0.7801\n",
      "Val Loss:   0.6334 | Val Metric (recall):   0.8396\n",
      "  - pathmnist: F1 = 0.9307, Recall = 0.9308\n",
      "  - dermamnist: F1 = 0.4328, Recall = 0.4036\n",
      "  - octmnist: F1 = 0.8883, Recall = 0.8740\n",
      "  - pneumoniamnist: F1 = 0.9517, Recall = 0.9670\n",
      "  - retinamnist: F1 = 0.3622, Recall = 0.3584\n",
      "  - breastmnist: F1 = 0.8608, Recall = 0.8396\n",
      "  - bloodmnist: F1 = 0.9408, Recall = 0.9445\n",
      "  - tissuemnist: F1 = 0.6143, Recall = 0.6031\n",
      "  - organamnist: F1 = 0.9929, Recall = 0.9926\n",
      "  - organcmnist: F1 = 0.9896, Recall = 0.9892\n",
      "  - organsmnist: F1 = 0.8449, Recall = 0.8451\n",
      "Saved best model.\n",
      "\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [17:45<00:00,  1.24s/it, loss=0.335]\n",
      "Validating: 100%|██████████| 116/116 [01:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3345 | Train F1 (Harmonic): 0.7768\n",
      "Val Loss:   0.6165 | Val Metric (recall):   0.8008\n",
      "  - pathmnist: F1 = 0.9316, Recall = 0.9316\n",
      "  - dermamnist: F1 = 0.4267, Recall = 0.3996\n",
      "  - octmnist: F1 = 0.8929, Recall = 0.8822\n",
      "  - pneumoniamnist: F1 = 0.9610, Recall = 0.9722\n",
      "  - retinamnist: F1 = 0.3613, Recall = 0.3612\n",
      "  - breastmnist: F1 = 0.8342, Recall = 0.8008\n",
      "  - bloodmnist: F1 = 0.9418, Recall = 0.9440\n",
      "  - tissuemnist: F1 = 0.6212, Recall = 0.6133\n",
      "  - organamnist: F1 = 0.9938, Recall = 0.9935\n",
      "  - organcmnist: F1 = 0.9881, Recall = 0.9893\n",
      "  - organsmnist: F1 = 0.8551, Recall = 0.8602\n",
      "Early stopping counter: 1/7\n",
      "\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [17:59<00:00,  1.26s/it, loss=0.322]\n",
      "Validating: 100%|██████████| 116/116 [01:21<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3221 | Train F1 (Harmonic): 0.7949\n",
      "Val Loss:   0.6159 | Val Metric (recall):   0.8333\n",
      "  - pathmnist: F1 = 0.9345, Recall = 0.9350\n",
      "  - dermamnist: F1 = 0.4278, Recall = 0.3990\n",
      "  - octmnist: F1 = 0.8956, Recall = 0.8804\n",
      "  - pneumoniamnist: F1 = 0.9610, Recall = 0.9722\n",
      "  - retinamnist: F1 = 0.3545, Recall = 0.3512\n",
      "  - breastmnist: F1 = 0.8711, Recall = 0.8333\n",
      "  - bloodmnist: F1 = 0.9425, Recall = 0.9443\n",
      "  - tissuemnist: F1 = 0.6269, Recall = 0.6202\n",
      "  - organamnist: F1 = 0.9928, Recall = 0.9924\n",
      "  - organcmnist: F1 = 0.9886, Recall = 0.9889\n",
      "  - organsmnist: F1 = 0.8529, Recall = 0.8558\n",
      "Early stopping counter: 2/7\n",
      "\n",
      "Epoch 29/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [17:59<00:00,  1.26s/it, loss=0.318]\n",
      "Validating: 100%|██████████| 116/116 [01:22<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3184 | Train F1 (Harmonic): 0.7815\n",
      "Val Loss:   0.6158 | Val Metric (recall):   0.8095\n",
      "  - pathmnist: F1 = 0.9335, Recall = 0.9337\n",
      "  - dermamnist: F1 = 0.4531, Recall = 0.4252\n",
      "  - octmnist: F1 = 0.8981, Recall = 0.8849\n",
      "  - pneumoniamnist: F1 = 0.9634, Recall = 0.9735\n",
      "  - retinamnist: F1 = 0.3734, Recall = 0.3684\n",
      "  - breastmnist: F1 = 0.8496, Recall = 0.8095\n",
      "  - bloodmnist: F1 = 0.9417, Recall = 0.9439\n",
      "  - tissuemnist: F1 = 0.6260, Recall = 0.6193\n",
      "  - organamnist: F1 = 0.9930, Recall = 0.9926\n",
      "  - organcmnist: F1 = 0.9898, Recall = 0.9897\n",
      "  - organsmnist: F1 = 0.8537, Recall = 0.8552\n",
      "Early stopping counter: 3/7\n",
      "\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/859 [00:00<?, ?it/s]<ipython-input-2-596e5a40956e>:305: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=self.config['use_amp']):\n",
      "Training: 100%|██████████| 859/859 [18:03<00:00,  1.26s/it, loss=0.316]\n",
      "Validating: 100%|██████████| 116/116 [01:21<00:00,  1.42it/s]\n",
      "<ipython-input-2-596e5a40956e>:520: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3164 | Train F1 (Harmonic): 0.7905\n",
      "Val Loss:   0.6168 | Val Metric (recall):   0.8333\n",
      "  - pathmnist: F1 = 0.9332, Recall = 0.9334\n",
      "  - dermamnist: F1 = 0.4524, Recall = 0.4235\n",
      "  - octmnist: F1 = 0.8985, Recall = 0.8855\n",
      "  - pneumoniamnist: F1 = 0.9634, Recall = 0.9735\n",
      "  - retinamnist: F1 = 0.3660, Recall = 0.3612\n",
      "  - breastmnist: F1 = 0.8711, Recall = 0.8333\n",
      "  - bloodmnist: F1 = 0.9418, Recall = 0.9443\n",
      "  - tissuemnist: F1 = 0.6255, Recall = 0.6198\n",
      "  - organamnist: F1 = 0.9928, Recall = 0.9924\n",
      "  - organcmnist: F1 = 0.9888, Recall = 0.9887\n",
      "  - organsmnist: F1 = 0.8540, Recall = 0.8554\n",
      "Early stopping counter: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-596e5a40956e>:545: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), autocast(enabled=config['use_amp']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from epoch 25 with metric: 0.8396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating predictions: 100%|██████████| 190/190 [00:41<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission saved with 96941 total predictions\n",
      "   id  label  task_name  id_image_in_task\n",
      "0   0      8  pathmnist                 0\n",
      "1   1      4  pathmnist                 1\n",
      "2   2      4  pathmnist                 2\n",
      "3   3      3  pathmnist                 3\n",
      "4   4      4  pathmnist                 4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import torch\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from pathlib import Path\n",
    "import random\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import f1_score, recall_score  # recall_score 추가\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- Configuration ---\n",
    "config = {\n",
    "    'backbone': 'convnext_tiny.in12k_ft_in1k',\n",
    "    'pretrained': True,\n",
    "    'batch_size': 512,\n",
    "    'num_epochs': 30,\n",
    "    'lr': 1e-3,\n",
    "    'optimizer': 'AdamW',\n",
    "    'weight_decay': 0.05,\n",
    "    'gradient_clip_norm': 1.0,\n",
    "    'early_stopping_patience': 7,\n",
    "    'scheduler': 'onecycle',\n",
    "    'num_workers': 4,\n",
    "    'use_amp': True,\n",
    "    'head_type': 'bottleneck',\n",
    "    'dropout_rate': 0.2,\n",
    "    'stochastic_depth_rate': 0.1,\n",
    "    'use_focal_loss': False,  # Focal Loss 사용 여부\n",
    "    'focal_loss_gamma': 2.0, # Focal Loss 감마 값\n",
    "    'early_stopping_target_task': 'breastmnist',  # 조기 종료 기준 작업\n",
    "    'early_stopping_metric': 'recall',  # 조기 종료 기준 지표 (recall 또는 f1)\n",
    "}\n",
    "\n",
    "DEBUG = False  # Set to True for faster debugging (fewer epochs/data)\n",
    "if DEBUG:\n",
    "    config['num_epochs'] = 1\n",
    "    config['batch_size'] = 64\n",
    "\n",
    "# --- Data Loading ---\n",
    "def load_medmnist_from_npz(data_flag, debug=False):\n",
    "    data_path = Path('/kaggle/input/tensor-reloaded-multi-task-med-mnist/data') / f'{data_flag}.npz'\n",
    "    data = np.load(data_path)\n",
    "    info = INFO[data_flag]\n",
    "    n_classes = len(info['label'])\n",
    "\n",
    "    class NPZDataset(Dataset):\n",
    "        def __init__(self, images, labels=None):\n",
    "            self.images = images\n",
    "            self.labels = labels\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            image = self.images[idx]\n",
    "            label = self.labels[idx] if self.labels is not None else None\n",
    "            return image, label  # Return NumPy arrays\n",
    "\n",
    "    if debug:\n",
    "        # Use a smaller subset of the training data for debugging\n",
    "        train_size = len(data['train_images'])\n",
    "        indices = list(range(train_size))\n",
    "        random.seed(42)  # For reproducibility\n",
    "        debug_size = int(0.1 * train_size)  # Use 10% of the data\n",
    "        debug_indices = random.sample(indices, debug_size)\n",
    "\n",
    "        train_images = data['train_images'][debug_indices]\n",
    "        train_labels = data['train_labels'][debug_indices] if 'train_labels' in data else None\n",
    "        train_dataset = NPZDataset(train_images, train_labels)\n",
    "    else:\n",
    "        train_dataset = NPZDataset(data['train_images'], data.get('train_labels'))\n",
    "\n",
    "    val_dataset = NPZDataset(data['val_images'], data.get('val_labels'))\n",
    "    test_dataset = NPZDataset(data['test_images'], data.get('test_labels'))  # Include test labels\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, info\n",
    "\n",
    "DATASETS = [\n",
    "    'pathmnist', 'dermamnist', 'octmnist', 'pneumoniamnist', 'retinamnist',\n",
    "    'breastmnist', 'bloodmnist', 'tissuemnist', 'organamnist', 'organcmnist',\n",
    "    'organsmnist'\n",
    "]\n",
    "\n",
    "def load_all_datasets(debug=False):\n",
    "    datasets = {}\n",
    "    for data_flag in DATASETS:\n",
    "        print(f\"Loading {data_flag}...\")\n",
    "        train, val, test, info = load_medmnist_from_npz(data_flag, debug=debug)\n",
    "        datasets[data_flag] = {\n",
    "            'train': train,\n",
    "            'val': val,\n",
    "            'test': test,\n",
    "            'info': info\n",
    "        }\n",
    "    return datasets\n",
    "\n",
    "def calculate_class_weights(datasets):\n",
    "    weights = {}\n",
    "    for data_flag in DATASETS:\n",
    "        labels = datasets[data_flag]['train'].labels\n",
    "        if labels is None:  # Handle cases where labels are missing\n",
    "            weights[data_flag] = None\n",
    "            continue\n",
    "        if isinstance(labels, torch.Tensor):\n",
    "            labels = labels.numpy()  # Convert to NumPy array if needed\n",
    "        num_classes = len(datasets[data_flag]['info']['label'])\n",
    "        class_counts = np.bincount(labels.flatten(), minlength=num_classes)\n",
    "        total = class_counts.sum()\n",
    "        raw_weights = total / (class_counts + 1e-6)  # Avoid division by zero\n",
    "        normalized_weights = raw_weights / raw_weights.mean()  # Normalize\n",
    "        weights[data_flag] = torch.FloatTensor(normalized_weights)\n",
    "    return weights\n",
    "\n",
    "# --- Model Definition ---\n",
    "class SelfAttention(nn.Module):\n",
    "    \"\"\"Simple self-attention layer.\"\"\"\n",
    "    def __init__(self, dim, heads=8, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5  # Scaled dot-product attention\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)  # Learnable projections\n",
    "        self.attend = nn.Softmax(dim=-1)  # Softmax for attention weights\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.to_out = nn.Sequential(nn.Linear(dim, dim), nn.Dropout(dropout))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)  # Split into Q, K, V\n",
    "        q, k, v = map(lambda t: t.reshape(b, n, h, -1).permute(0, 2, 1, 3), qkv)\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale  # Scaled dot product\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "        out = torch.matmul(attn, v)  # Weighted sum of values\n",
    "        out = out.permute(0, 2, 1, 3).reshape(b, n, -1)  # Concatenate heads\n",
    "        return self.to_out(out)\n",
    "\n",
    "class MedMNISTMultiTaskModel(nn.Module):\n",
    "    def __init__(self, backbone_name, pretrained, head_type, dropout_rate, stochastic_depth_rate):\n",
    "        super().__init__()\n",
    "        self.task_outputs = {d: len(INFO[d]['label']) for d in DATASETS}\n",
    "        self.backbone = timm.create_model(\n",
    "            backbone_name, pretrained=pretrained, num_classes=0, drop_path_rate=stochastic_depth_rate\n",
    "        )\n",
    "        # Adapt the input layer to handle potential grayscale images:\n",
    "        self.backbone.stem[0] = nn.Conv2d(3, self.backbone.stem[0].out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        feat_dim = self.backbone.num_features  # Get feature dimension from backbone\n",
    "\n",
    "        self.heads = nn.ModuleDict()\n",
    "        for task, num_classes in self.task_outputs.items():\n",
    "            if head_type == 'simple':\n",
    "                head = nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, num_classes)\n",
    "                )\n",
    "            elif head_type == 'bottleneck':\n",
    "                head = nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, feat_dim // 4),\n",
    "                    nn.GELU(),\n",
    "                    nn.Dropout(dropout_rate),\n",
    "                    nn.Linear(feat_dim // 4, num_classes)\n",
    "                )\n",
    "            elif head_type == 'attention':\n",
    "                head = nn.Sequential(\n",
    "                    nn.LayerNorm(feat_dim),\n",
    "                    nn.Linear(feat_dim, feat_dim//2),\n",
    "                    nn.GELU(),\n",
    "                    SelfAttention(feat_dim//2, heads=4, dropout=dropout_rate),\n",
    "                    nn.Linear(feat_dim // 2, num_classes)\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid head_type: {head_type}\")\n",
    "            self.heads[task] = head\n",
    "\n",
    "    def forward(self, x, task_ids=None):\n",
    "        features = self.backbone(x)\n",
    "        if task_ids is not None:  # Training/validation: task-specific outputs\n",
    "            outputs = torch.zeros(len(task_ids), max(self.task_outputs.values())).to(features.device)\n",
    "            for i, task_id in enumerate(task_ids):\n",
    "                task_name = DATASETS[task_id]\n",
    "                task_output = self.heads[task_name](features[i:i+1])\n",
    "                outputs[i, :self.task_outputs[task_name]] = task_output.squeeze(0)\n",
    "            return outputs\n",
    "        else:  # Potentially for inference/feature extraction\n",
    "            return {task: head(features) for task, head in self.heads.items()}\n",
    "\n",
    "# --- Dataset ---\n",
    "class MedMNISTMultiDataset(Dataset):\n",
    "    def __init__(self, datasets, split='train', transform=None):\n",
    "        super().__init__()\n",
    "        self.datasets = datasets\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "        self.dataset_indices = []\n",
    "        # Create a combined list of (dataset_index, sample_index)\n",
    "        for dataset_idx, (name, dataset_dict) in enumerate(datasets.items()):\n",
    "            dataset = dataset_dict[split]\n",
    "            n_samples = len(dataset)\n",
    "            self.dataset_indices.extend([(dataset_idx, i) for i in range(n_samples)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dataset_idx, sample_idx = self.dataset_indices[idx]\n",
    "        dataset_name = DATASETS[dataset_idx]\n",
    "        dataset = self.datasets[dataset_name][self.split]\n",
    "        image, label = dataset[sample_idx]  # Get NumPy arrays\n",
    "\n",
    "        # Convert NumPy array to PIL Image\n",
    "        if isinstance(image, np.ndarray):\n",
    "            # Handle both grayscale (H, W) and color (H, W, C) images\n",
    "            if image.ndim == 2:  # Grayscale\n",
    "                image = transforms.functional.to_pil_image(image, mode='L') # Explicitly specify mode\n",
    "            elif image.ndim == 3:\n",
    "                 # Transpose if channels are first\n",
    "                if image.shape[0] in [1, 3]:\n",
    "                    image = image.transpose(1, 2, 0)\n",
    "                image = transforms.functional.to_pil_image(image)\n",
    "\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transforms\n",
    "\n",
    "        # Convert label to tensor if it exists\n",
    "        if label is not None:\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "        else:\n",
    "            label = torch.tensor(-1, dtype=torch.long)  # Dummy label for test set\n",
    "\n",
    "        return image, label, torch.tensor(dataset_idx, dtype=torch.long)  # Return task ID\n",
    "\n",
    "# --- Trainer ---\n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataset, val_dataset, config, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.config = config\n",
    "        self.scaler = GradScaler(enabled=config['use_amp']) # Use standard GradScaler\n",
    "        # 조기 종료 기준 관련 변수 초기화\n",
    "        if self.config['early_stopping_metric'] == 'recall':\n",
    "          self.best_val_metric = 0.0\n",
    "        elif self.config[\"early_stopping_metric\"] == \"f1\":\n",
    "          self.best_val_metric = 0.0  # Assuming higher is better (e.g., F1 score)\n",
    "        self.early_stopping_counter = 0\n",
    "        self.train_loader = DataLoader(\n",
    "            train_dataset, batch_size=config['batch_size'], shuffle=True,\n",
    "            num_workers=config['num_workers'], pin_memory=True, persistent_workers=True\n",
    "        )\n",
    "        self.val_loader = DataLoader(\n",
    "            val_dataset, batch_size=config['batch_size'], shuffle=False,\n",
    "            num_workers=config['num_workers'], pin_memory=True, persistent_workers=True\n",
    "        )\n",
    "        self.class_weights = calculate_class_weights(datasets)\n",
    "\n",
    "        # Optimizer\n",
    "        if config['optimizer'] == 'AdamW':\n",
    "            self.optimizer = AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid optimizer: {config['optimizer']}\")\n",
    "\n",
    "        # Scheduler\n",
    "        if config['scheduler'] == 'onecycle':\n",
    "            self.scheduler = OneCycleLR(\n",
    "                self.optimizer, max_lr=config['lr'], epochs=config['num_epochs'],\n",
    "                steps_per_epoch=len(self.train_loader)\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid scheduler: {config['scheduler']}\")\n",
    "\n",
    "        # Loss function (Focal Loss or CrossEntropyLoss)\n",
    "        if config['use_focal_loss']:\n",
    "            self.criterion = self.focal_loss  # Use the defined focal_loss method\n",
    "        else:\n",
    "            self.criterion = torch.nn.CrossEntropyLoss() # Default criterion\n",
    "\n",
    "    # Focal Loss implementation (as a method within Trainer)\n",
    "    def focal_loss(self, outputs, labels, class_weights=None):\n",
    "        gamma = self.config['focal_loss_gamma']\n",
    "        ce_loss = F.cross_entropy(outputs, labels, reduction='none', weight=class_weights)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (1 - pt)**gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        task_predictions = {task: {'preds': [], 'targets': []} for task in DATASETS}\n",
    "        pbar = tqdm(self.train_loader, desc='Training', dynamic_ncols=True)\n",
    "\n",
    "        for images, labels, task_ids in pbar:\n",
    "            images, labels, task_ids = images.to(self.device), labels.to(self.device), task_ids.to(self.device)\n",
    "\n",
    "            with autocast(enabled=self.config['use_amp']):\n",
    "                outputs = self.model(images, task_ids)\n",
    "                losses = []\n",
    "                for i, (output, label, task_id) in enumerate(zip(outputs, labels, task_ids)):\n",
    "                    task_name = DATASETS[task_id]\n",
    "                    num_classes = self.model.task_outputs[task_name]\n",
    "                    task_output = output[:num_classes].unsqueeze(0)  # Ensure correct shape\n",
    "                    task_label = label.view(-1) # Ensure correct shape\n",
    "\n",
    "                    class_weight = self.class_weights.get(task_name)\n",
    "                    if class_weight is not None:\n",
    "                        class_weight = class_weight.to(self.device)\n",
    "\n",
    "                    # Use Focal Loss if enabled, otherwise use CrossEntropyLoss\n",
    "                    if self.config['use_focal_loss']:\n",
    "                      loss = self.focal_loss(task_output, task_label, class_weight)\n",
    "                    else:\n",
    "                      loss_fn = torch.nn.CrossEntropyLoss(weight=class_weight)\n",
    "                      loss = loss_fn(task_output, task_label)\n",
    "\n",
    "                    losses.append(loss)\n",
    "\n",
    "                loss = torch.stack(losses).mean() # Use mean for multi-task loss\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            self.scaler.scale(loss).backward()\n",
    "            clip_grad_norm_(self.model.parameters(), self.config['gradient_clip_norm'])\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': total_loss / (pbar.n + 1)})\n",
    "\n",
    "            for i, (output, label, task_id) in enumerate(zip(outputs, labels, task_ids)):\n",
    "                task_name = DATASETS[task_id]\n",
    "                num_classes = self.model.task_outputs[task_name]\n",
    "                pred = output[:num_classes].argmax(dim=0).cpu().item()\n",
    "                target = label.item()\n",
    "                task_predictions[task_name]['preds'].append(pred)\n",
    "                task_predictions[task_name]['targets'].append(target)\n",
    "\n",
    "        # Calculate F1 scores for each task\n",
    "        task_f1_scores = {\n",
    "            task: f1_score(task_predictions[task]['targets'], task_predictions[task]['preds'], average='macro')\n",
    "            if len(task_predictions[task]['preds']) > 0 else 0.0 for task in DATASETS\n",
    "        }\n",
    "        return total_loss / len(self.train_loader), task_f1_scores\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        task_predictions = {task: {'preds': [], 'targets': []} for task in DATASETS}\n",
    "\n",
    "        pbar = tqdm(self.val_loader, desc='Validating', dynamic_ncols=True)\n",
    "        for images, labels, task_ids in pbar:\n",
    "            images, labels, task_ids = images.to(self.device), labels.to(self.device), task_ids.to(self.device)\n",
    "            labels = labels.view(-1).long()  # Flatten labels\n",
    "            outputs = self.model(images, task_ids)\n",
    "            losses = []\n",
    "\n",
    "            for task_name in set(DATASETS[tid.item()] for tid in task_ids):  # Iterate through unique tasks\n",
    "                task_mask = torch.tensor([DATASETS[tid.item()] == task_name for tid in task_ids], device=self.device)\n",
    "                if not task_mask.any():  # Skip if no samples for this task in batch\n",
    "                    continue\n",
    "                task_outputs = outputs[task_mask]\n",
    "                task_labels = labels[task_mask]\n",
    "                n_classes = self.model.task_outputs[task_name]\n",
    "\n",
    "                class_weight = self.class_weights.get(task_name)  # Use .get()\n",
    "                if class_weight is not None:\n",
    "                    class_weight = class_weight.to(self.device)\n",
    "\n",
    "                # Use Focal Loss if enabled\n",
    "                if self.config['use_focal_loss']:\n",
    "                    task_loss = self.focal_loss(task_outputs[:, :n_classes], task_labels, class_weight)\n",
    "                else:\n",
    "                    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weight)\n",
    "                    task_loss = loss_fn(task_outputs[:, :n_classes], task_labels)\n",
    "\n",
    "                losses.append(task_loss)\n",
    "\n",
    "            loss = torch.stack(losses).mean() # Use mean for multi-task loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            for i, (task_id, label) in enumerate(zip(task_ids, labels)):\n",
    "                task_name = DATASETS[task_id.item()]\n",
    "                n_classes = self.model.task_outputs[task_name]\n",
    "                pred = outputs[i, :n_classes].argmax(dim=0).cpu().item()\n",
    "                task_predictions[task_name]['preds'].append(pred)\n",
    "                task_predictions[task_name]['targets'].append(label.cpu().item())\n",
    "\n",
    "        # Calculate F1 scores and Recall for each task.\n",
    "        task_f1_scores = {}\n",
    "        task_recall_scores = {} # recall 추가\n",
    "        for task in DATASETS:\n",
    "            if len(task_predictions[task]['preds']) > 0:\n",
    "                task_f1_scores[task] = f1_score(task_predictions[task]['targets'], task_predictions[task]['preds'], average='macro')\n",
    "                task_recall_scores[task] = recall_score(task_predictions[task]['targets'], task_predictions[task]['preds'], average='macro') # recall 계산\n",
    "            else:\n",
    "                task_f1_scores[task] = 0.0\n",
    "                task_recall_scores[task] = 0.0\n",
    "\n",
    "        # 조기 종료 metric 계산\n",
    "        if self.config['early_stopping_metric'] == 'recall':\n",
    "          target_task = self.config['early_stopping_target_task']\n",
    "          val_metric = task_recall_scores[target_task] if target_task in task_recall_scores else 0.0\n",
    "\n",
    "        elif self.config['early_stopping_metric'] == 'f1':\n",
    "            # Compute the *harmonic mean* of the F1 scores.\n",
    "            val_f1_values = list(task_f1_scores.values())\n",
    "            val_metric = len(val_f1_values) / sum(1 / f1 if f1 > 0 else 1e-6 for f1 in val_f1_values)\n",
    "\n",
    "        return total_loss / len(self.val_loader), val_metric, task_f1_scores, task_recall_scores  # Return individual task scores\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.config['num_epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['num_epochs']}\")\n",
    "            train_loss, train_f1_scores = self.train_epoch()\n",
    "            val_loss, val_metric, val_f1_scores, val_recall_scores = self.validate()\n",
    "\n",
    "            # Calculate harmonic mean of training F1 scores\n",
    "            train_f1_values = list(train_f1_scores.values())\n",
    "            train_f1_mean = len(train_f1_values) / sum(1 / f1 if f1 > 0 else 1e-6 for f1 in train_f1_values)\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f} | Train F1 (Harmonic): {train_f1_mean:.4f}\")\n",
    "            print(f\"Val Loss:   {val_loss:.4f} | Val Metric ({self.config['early_stopping_metric']}):   {val_metric:.4f}\")\n",
    "\n",
    "            # Print individual task F1 scores and recall scores\n",
    "            for task in DATASETS:\n",
    "                if task in val_f1_scores:\n",
    "                    print(f\"  - {task}: F1 = {val_f1_scores[task]:.4f}, Recall = {val_recall_scores[task]:.4f}\")  # recall 출력\n",
    "\n",
    "            if val_metric > self.best_val_metric:\n",
    "                self.best_val_metric = val_metric\n",
    "                self.early_stopping_counter = 0\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "                    'best_metric': self.best_val_metric,  # best_f1 대신 best_metric\n",
    "                    'config': self.config,\n",
    "                }, 'best_model.pth')\n",
    "                print(\"Saved best model.\")\n",
    "            else:\n",
    "                self.early_stopping_counter += 1\n",
    "                print(f\"Early stopping counter: {self.early_stopping_counter}/{self.config['early_stopping_patience']}\")\n",
    "                if self.early_stopping_counter >= self.config['early_stopping_patience']:\n",
    "                    print(\"Early stopping triggered.\")\n",
    "                    break\n",
    "\n",
    "# --- Data Augmentation ---\n",
    "# Data augmentation transforms: consistent 3-channel input\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(28, 28), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "    transforms.RandomRotation(degrees=(-15, 15)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    # For validation/test, we usually just resize and normalize\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "# --- Load Data, Create Datasets, Model, and Trainer ---\n",
    "datasets = load_all_datasets(debug=DEBUG)\n",
    "\n",
    "# Add Grayscale transform *before* ToTensor and Normalize\n",
    "def get_transforms(train=True):\n",
    "  transforms_list = []\n",
    "  if train:\n",
    "    transforms_list.extend([\n",
    "        transforms.RandomResizedCrop(size=(28, 28), scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "        transforms.RandomRotation(degrees=(-15, 15)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.05),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "    ])\n",
    "  # else:  # No additional transforms needed for val/test besides Grayscale and Normalize\n",
    "      # transforms_list.extend([])\n",
    "  transforms_list.extend([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels *BEFORE* normalization\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "  ])\n",
    "  return transforms.Compose(transforms_list)\n",
    "\n",
    "\n",
    "train_dataset = MedMNISTMultiDataset(datasets, split='train', transform=get_transforms(train=True))\n",
    "val_dataset = MedMNISTMultiDataset(datasets, split='val', transform=get_transforms(train=False))\n",
    "test_dataset = MedMNISTMultiDataset(datasets, split='test', transform=get_transforms(train=False))\n",
    "\n",
    "model = MedMNISTMultiTaskModel(\n",
    "    backbone_name=config['backbone'],\n",
    "    pretrained=config['pretrained'],\n",
    "    head_type=config['head_type'],\n",
    "    dropout_rate=config['dropout_rate'],\n",
    "    stochastic_depth_rate=config['stochastic_depth_rate']\n",
    ")\n",
    "trainer = Trainer(model, train_dataset, val_dataset, config)\n",
    "\n",
    "# --- Train the Model ---\n",
    "trainer.train()\n",
    "\n",
    "# --- Submission Generation (Example - Adapt as Needed) ---\n",
    "def load_best_model(checkpoint_path, model, device='cuda'):\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_metric = checkpoint['best_metric'] # best_f1 대신 best_metric\n",
    "        print(f\"Loaded best model from epoch {checkpoint['epoch']} with metric: {best_metric:.4f}\") # metric 종류 출력\n",
    "        return model, best_metric\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No checkpoint found at {checkpoint_path}\")\n",
    "        return None, 0.0  # Or handle the error as appropriate\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {str(e)}\")\n",
    "        return None, 0.0\n",
    "def create_submission(model, test_dataset, config, device='cuda'):\n",
    "    if model is None:  # Check if the model is loaded\n",
    "        print(\"Cannot create submission: No model loaded.\")\n",
    "        return None\n",
    "\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=config['batch_size'], shuffle=False,\n",
    "        num_workers=config['num_workers'], pin_memory=True, persistent_workers=True\n",
    "    )\n",
    "    task_counters = {task: 0 for task in DATASETS}\n",
    "    global_id = 0 # global id\n",
    "\n",
    "    with torch.no_grad(), autocast(enabled=config['use_amp']):\n",
    "        for batch in tqdm(test_loader, desc='Generating predictions', dynamic_ncols=True):\n",
    "            images, _, task_ids = batch  # Unpack the batch, ignore labels\n",
    "            images, task_ids = images.to(device, non_blocking=True), task_ids.to(device, non_blocking=True)\n",
    "            unique_tasks = torch.unique(task_ids)\n",
    "\n",
    "            for task_idx in unique_tasks:\n",
    "                task_name = DATASETS[task_idx]\n",
    "                # Filter the batch to only include samples from the current task\n",
    "                mask = task_ids == task_idx\n",
    "                if mask.any():  # Ensure there are samples for this task\n",
    "                  task_images = images[mask]\n",
    "                  features = model.backbone(task_images)\n",
    "                  outputs = model.heads[task_name](features)\n",
    "                  preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "                  n_preds = len(preds)\n",
    "\n",
    "                  task_start_idx = task_counters[task_name]\n",
    "\n",
    "                  # Create a list of dictionaries for this batch\n",
    "                  batch_predictions = [\n",
    "                      {\n",
    "                          'id': global_id + i,\n",
    "                          'label': int(pred),  # Convert to int\n",
    "                          'task_name': task_name,  # Store task name\n",
    "                          'id_image_in_task': task_start_idx + i,\n",
    "                      }\n",
    "                      for i, pred in enumerate(preds)\n",
    "                  ]\n",
    "                  all_predictions.extend(batch_predictions)\n",
    "                  task_counters[task_name] += n_preds\n",
    "                  global_id += n_preds\n",
    "\n",
    "\n",
    "    # Convert to DataFrame and save\n",
    "    df = pd.DataFrame(all_predictions)\n",
    "    df = df[['id', 'label', 'task_name', 'id_image_in_task']]  # Ensure correct column order\n",
    "    df.to_csv('submission.csv', index=False)\n",
    "    print(f\"\\nSubmission saved with {len(df)} total predictions\")\n",
    "    return df\n",
    "# --- Load Best Model and Create Submission ---\n",
    "\n",
    "model, best_metric = load_best_model('best_model.pth', model)  # best_f1 대신 best_metric\n",
    "submission_df = create_submission(model, test_dataset, config)\n",
    "\n",
    "if submission_df is not None:\n",
    "  print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9915460,
     "sourceId": 86864,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32594.072201,
   "end_time": "2025-02-19T21:38:26.066257",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T12:35:11.994056",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "05711d63f4144609ab96aa62b9c42b52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a63651874d84ef0a783d7f41f072039": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_57ae8795cbfe4e42886b49dc06db9452",
        "IPY_MODEL_ed2cb5a80b6c4881abea5242ece37482",
        "IPY_MODEL_f8977a2035a546f9932673694adbf754"
       ],
       "layout": "IPY_MODEL_31a6c8ae174c45a286ff4f02651bb09c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "224bbfa881024544b76bb07b58d9b80f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "31a6c8ae174c45a286ff4f02651bb09c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4414a82050d744aa9909c4077c382fdf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56f9d6a1396148868b36cea313e545ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "57ae8795cbfe4e42886b49dc06db9452": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_05711d63f4144609ab96aa62b9c42b52",
       "placeholder": "​",
       "style": "IPY_MODEL_b647e93f59764b029083ad1aab03f94b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "a3e804c107eb4311a946265989b6f09d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b647e93f59764b029083ad1aab03f94b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ed2cb5a80b6c4881abea5242ece37482": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a3e804c107eb4311a946265989b6f09d",
       "max": 114374272.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_56f9d6a1396148868b36cea313e545ce",
       "tabbable": null,
       "tooltip": null,
       "value": 114374272.0
      }
     },
     "f8977a2035a546f9932673694adbf754": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4414a82050d744aa9909c4077c382fdf",
       "placeholder": "​",
       "style": "IPY_MODEL_224bbfa881024544b76bb07b58d9b80f",
       "tabbable": null,
       "tooltip": null,
       "value": " 114M/114M [00:00&lt;00:00, 153MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
